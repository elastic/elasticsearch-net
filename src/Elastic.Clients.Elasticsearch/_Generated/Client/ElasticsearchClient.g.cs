// Licensed to Elasticsearch B.V under one or more agreements.
// Elasticsearch B.V licenses this file to you under the Apache 2.0 License.
// See the LICENSE file in the project root for more information.
//
// ███╗   ██╗ ██████╗ ████████╗██╗ ██████╗███████╗
// ████╗  ██║██╔═══██╗╚══██╔══╝██║██╔════╝██╔════╝
// ██╔██╗ ██║██║   ██║   ██║   ██║██║     █████╗
// ██║╚██╗██║██║   ██║   ██║   ██║██║     ██╔══╝
// ██║ ╚████║╚██████╔╝   ██║   ██║╚██████╗███████╗
// ╚═╝  ╚═══╝ ╚═════╝    ╚═╝   ╚═╝ ╚═════╝╚══════╝
// ------------------------------------------------
//
// This file is automatically generated.
// Please do not edit these files manually.
//
// ------------------------------------------------

#nullable restore

using Elastic.Clients.Elasticsearch.AsyncSearch;
using Elastic.Clients.Elasticsearch.Cluster;
using Elastic.Clients.Elasticsearch.CrossClusterReplication;
using Elastic.Clients.Elasticsearch.DanglingIndices;
using Elastic.Clients.Elasticsearch.Enrich;
using Elastic.Clients.Elasticsearch.Eql;
using Elastic.Clients.Elasticsearch.Esql;
using Elastic.Clients.Elasticsearch.Features;
using Elastic.Clients.Elasticsearch.Graph;
using Elastic.Clients.Elasticsearch.IndexLifecycleManagement;
using Elastic.Clients.Elasticsearch.IndexManagement;
using Elastic.Clients.Elasticsearch.Inference;
using Elastic.Clients.Elasticsearch.Ingest;
using Elastic.Clients.Elasticsearch.LicenseManagement;
using Elastic.Clients.Elasticsearch.MachineLearning;
using Elastic.Clients.Elasticsearch.Nodes;
using Elastic.Clients.Elasticsearch.QueryRules;
using Elastic.Clients.Elasticsearch.Rollup;
using Elastic.Clients.Elasticsearch.SearchableSnapshots;
using Elastic.Clients.Elasticsearch.SearchApplication;
using Elastic.Clients.Elasticsearch.Security;
using Elastic.Clients.Elasticsearch.Simulate;
using Elastic.Clients.Elasticsearch.Snapshot;
using Elastic.Clients.Elasticsearch.SnapshotLifecycleManagement;
using Elastic.Clients.Elasticsearch.Sql;
using Elastic.Clients.Elasticsearch.Synonyms;
using Elastic.Clients.Elasticsearch.Tasks;
using Elastic.Clients.Elasticsearch.TextStructure;
using Elastic.Clients.Elasticsearch.TransformManagement;
using Elastic.Clients.Elasticsearch.Xpack;
using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;

namespace Elastic.Clients.Elasticsearch;

public partial class ElasticsearchClient
{
	public virtual AsyncSearchNamespacedClient AsyncSearch { get; private set; }
	public virtual ClusterNamespacedClient Cluster { get; private set; }
	public virtual CrossClusterReplicationNamespacedClient CrossClusterReplication { get; private set; }
	public virtual DanglingIndicesNamespacedClient DanglingIndices { get; private set; }
	public virtual EnrichNamespacedClient Enrich { get; private set; }
	public virtual EqlNamespacedClient Eql { get; private set; }
	public virtual EsqlNamespacedClient Esql { get; private set; }
	public virtual FeaturesNamespacedClient Features { get; private set; }
	public virtual GraphNamespacedClient Graph { get; private set; }
	public virtual IndexLifecycleManagementNamespacedClient IndexLifecycleManagement { get; private set; }
	public virtual IndicesNamespacedClient Indices { get; private set; }
	public virtual InferenceNamespacedClient Inference { get; private set; }
	public virtual IngestNamespacedClient Ingest { get; private set; }
	public virtual LicenseManagementNamespacedClient LicenseManagement { get; private set; }
	public virtual MachineLearningNamespacedClient MachineLearning { get; private set; }
	public virtual NodesNamespacedClient Nodes { get; private set; }
	public virtual QueryRulesNamespacedClient QueryRules { get; private set; }
	public virtual RollupNamespacedClient Rollup { get; private set; }
	public virtual SearchableSnapshotsNamespacedClient SearchableSnapshots { get; private set; }
	public virtual SearchApplicationNamespacedClient SearchApplication { get; private set; }
	public virtual SecurityNamespacedClient Security { get; private set; }
	public virtual SimulateNamespacedClient Simulate { get; private set; }
	public virtual SnapshotNamespacedClient Snapshot { get; private set; }
	public virtual SnapshotLifecycleManagementNamespacedClient SnapshotLifecycleManagement { get; private set; }
	public virtual SqlNamespacedClient Sql { get; private set; }
	public virtual SynonymsNamespacedClient Synonyms { get; private set; }
	public virtual TasksNamespacedClient Tasks { get; private set; }
	public virtual TextStructureNamespacedClient TextStructure { get; private set; }
	public virtual TransformManagementNamespacedClient TransformManagement { get; private set; }
	public virtual XpackNamespacedClient Xpack { get; private set; }

	private partial void SetupNamespaces()
	{
		AsyncSearch = new AsyncSearchNamespacedClient(this);
		Cluster = new ClusterNamespacedClient(this);
		CrossClusterReplication = new CrossClusterReplicationNamespacedClient(this);
		DanglingIndices = new DanglingIndicesNamespacedClient(this);
		Enrich = new EnrichNamespacedClient(this);
		Eql = new EqlNamespacedClient(this);
		Esql = new EsqlNamespacedClient(this);
		Features = new FeaturesNamespacedClient(this);
		Graph = new GraphNamespacedClient(this);
		IndexLifecycleManagement = new IndexLifecycleManagementNamespacedClient(this);
		Indices = new IndicesNamespacedClient(this);
		Inference = new InferenceNamespacedClient(this);
		Ingest = new IngestNamespacedClient(this);
		LicenseManagement = new LicenseManagementNamespacedClient(this);
		MachineLearning = new MachineLearningNamespacedClient(this);
		Nodes = new NodesNamespacedClient(this);
		QueryRules = new QueryRulesNamespacedClient(this);
		Rollup = new RollupNamespacedClient(this);
		SearchableSnapshots = new SearchableSnapshotsNamespacedClient(this);
		SearchApplication = new SearchApplicationNamespacedClient(this);
		Security = new SecurityNamespacedClient(this);
		Simulate = new SimulateNamespacedClient(this);
		Snapshot = new SnapshotNamespacedClient(this);
		SnapshotLifecycleManagement = new SnapshotLifecycleManagementNamespacedClient(this);
		Sql = new SqlNamespacedClient(this);
		Synonyms = new SynonymsNamespacedClient(this);
		Tasks = new TasksNamespacedClient(this);
		TextStructure = new TextStructureNamespacedClient(this);
		TransformManagement = new TransformManagementNamespacedClient(this);
		Xpack = new XpackNamespacedClient(this);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk(BulkRequest request)
	{
		request.BeforeRequest();
		return DoRequest<BulkRequest, BulkResponse, BulkRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync(BulkRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<BulkRequest, BulkResponse, BulkRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk<TDocument>(BulkRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index)
	{
		var descriptor = new BulkRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, Action<BulkRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new BulkRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk<TDocument>()
	{
		var descriptor = new BulkRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk<TDocument>(Action<BulkRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new BulkRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk(BulkRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk(Elastic.Clients.Elasticsearch.IndexName? index)
	{
		var descriptor = new BulkRequestDescriptor(index);
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk(Elastic.Clients.Elasticsearch.IndexName? index, Action<BulkRequestDescriptor> configureRequest)
	{
		var descriptor = new BulkRequestDescriptor(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk()
	{
		var descriptor = new BulkRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual BulkResponse Bulk(Action<BulkRequestDescriptor> configureRequest)
	{
		var descriptor = new BulkRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync<TDocument>(BulkRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, Action<BulkRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync<TDocument>(Action<BulkRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor<TDocument>, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync(BulkRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync(Elastic.Clients.Elasticsearch.IndexName? index, CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync(Elastic.Clients.Elasticsearch.IndexName? index, Action<BulkRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Bulk index or delete documents.
	/// Perform multiple <c>index</c>, <c>create</c>, <c>delete</c>, and <c>update</c> actions in a single request.
	/// This reduces overhead and can greatly increase indexing speed.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To use the <c>create</c> action, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege. Data streams support only the <c>create</c> action.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>index</c> action, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>delete</c> action, you must have the <c>delete</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To use the <c>update</c> action, you must have the <c>index</c> or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a bulk API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To make the result of a bulk operation visible to search using the <c>refresh</c> parameter, you must have the <c>maintenance</c> or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The actions are specified in the request body using a newline delimited JSON (NDJSON) structure:
	/// </para>
	/// <code>
	/// action_and_meta_data\n
	/// optional_source\n
	/// action_and_meta_data\n
	/// optional_source\n
	/// ....
	/// action_and_meta_data\n
	/// optional_source\n
	/// </code>
	/// <para>
	/// The <c>index</c> and <c>create</c> actions expect a source on the next line and have the same semantics as the <c>op_type</c> parameter in the standard index API.
	/// A <c>create</c> action fails if a document with the same ID already exists in the target
	/// An <c>index</c> action adds or replaces a document as necessary.
	/// </para>
	/// <para>
	/// NOTE: Data streams support only the <c>create</c> action.
	/// To update or delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// An <c>update</c> action expects that the partial doc, upsert, and script and its options are specified on the next line.
	/// </para>
	/// <para>
	/// A <c>delete</c> action does not expect a source on the next line and has the same semantics as the standard delete API.
	/// </para>
	/// <para>
	/// NOTE: The final line of data must end with a newline character (<c>\n</c>).
	/// Each newline character may be preceded by a carriage return (<c>\r</c>).
	/// When sending NDJSON data to the <c>_bulk</c> endpoint, use a <c>Content-Type</c> header of <c>application/json</c> or <c>application/x-ndjson</c>.
	/// Because this format uses literal newline characters (<c>\n</c>) as delimiters, make sure that the JSON actions and sources are not pretty printed.
	/// </para>
	/// <para>
	/// If you provide a target in the request path, it is used for any actions that don't explicitly specify an <c>_index</c> argument.
	/// </para>
	/// <para>
	/// A note on the format: the idea here is to make processing as fast as possible.
	/// As some of the actions are redirected to other shards on other nodes, only <c>action_meta_data</c> is parsed on the receiving node side.
	/// </para>
	/// <para>
	/// Client libraries using this protocol should try and strive to do something similar on the client side, and reduce buffering as much as possible.
	/// </para>
	/// <para>
	/// There is no "correct" number of actions to perform in a single bulk request.
	/// Experiment with different settings to find the optimal size for your particular workload.
	/// Note that Elasticsearch limits the maximum size of a HTTP request to 100mb by default so clients must ensure that no request exceeds this size.
	/// It is not possible to index a single document that exceeds the size limit, so you must pre-process any such documents into smaller pieces before sending them to Elasticsearch.
	/// For instance, split documents into pages or chapters before indexing them, or store raw binary data in a system outside Elasticsearch and replace the raw data with a link to the external system in the documents that you send to Elasticsearch.
	/// </para>
	/// <para>
	/// <strong>Client suppport for bulk requests</strong>
	/// </para>
	/// <para>
	/// Some of the officially supported clients provide helpers to assist with bulk requests and reindexing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Go: Check out <c>esutil.BulkIndexer</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Perl: Check out <c>Search::Elasticsearch::Client::5_0::Bulk</c> and <c>Search::Elasticsearch::Client::5_0::Scroll</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Python: Check out <c>elasticsearch.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// JavaScript: Check out <c>client.helpers.*</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// .NET: Check out <c>BulkAllObservable</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// PHP: Check out bulk indexing.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// <strong>Submitting bulk requests with cURL</strong>
	/// </para>
	/// <para>
	/// If you're providing text file input to <c>curl</c>, you must use the <c>--data-binary</c> flag instead of plain <c>-d</c>.
	/// The latter doesn't preserve newlines. For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index" : { "_index" : "test", "_id" : "1" } }
	/// { "field1" : "value1" }
	/// $ curl -s -H "Content-Type: application/x-ndjson" -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
	/// {"took":7, "errors": false, "items":[{"index":{"_index":"test","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}
	/// </code>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Each <c>index</c> and <c>delete</c> action within a bulk API call may include the <c>if_seq_no</c> and <c>if_primary_term</c> parameters in their respective action and meta data lines.
	/// The <c>if_seq_no</c> and <c>if_primary_term</c> parameters control how operations are run, based on the last modification to existing documents. See Optimistic concurrency control for more details.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the version value using the <c>version</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_version</c> mapping.
	/// It also support the <c>version_type</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// Each bulk item can include the routing value using the <c>routing</c> field.
	/// It automatically follows the behavior of the index or delete operation based on the <c>_routing</c> mapping.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// <strong>Wait for active shards</strong>
	/// </para>
	/// <para>
	/// When making bulk calls, you can set the <c>wait_for_active_shards</c> parameter to require a minimum number of shard copies to be active before starting to process the bulk request.
	/// </para>
	/// <para>
	/// <strong>Refresh</strong>
	/// </para>
	/// <para>
	/// Control when the changes made by this request are visible to search.
	/// </para>
	/// <para>
	/// NOTE: Only the shards that receive the bulk request will be affected by refresh.
	/// Imagine a <c>_bulk?refresh=wait_for</c> request with three documents in it that happen to be routed to different shards in an index with five shards.
	/// The request will only wait for those three shards to refresh.
	/// The other two shards that make up the index do not participate in the <c>_bulk</c> request at all.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-bulk.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<BulkResponse> BulkAsync(Action<BulkRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new BulkRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<BulkRequestDescriptor, BulkResponse, BulkRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClearScrollResponse ClearScroll(ClearScrollRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ClearScrollRequest, ClearScrollResponse, ClearScrollRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClearScrollResponse> ClearScrollAsync(ClearScrollRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ClearScrollRequest, ClearScrollResponse, ClearScrollRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClearScrollResponse ClearScroll(ClearScrollRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ClearScrollRequestDescriptor, ClearScrollResponse, ClearScrollRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClearScrollResponse ClearScroll()
	{
		var descriptor = new ClearScrollRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<ClearScrollRequestDescriptor, ClearScrollResponse, ClearScrollRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClearScrollResponse ClearScroll(Action<ClearScrollRequestDescriptor> configureRequest)
	{
		var descriptor = new ClearScrollRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ClearScrollRequestDescriptor, ClearScrollResponse, ClearScrollRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClearScrollResponse> ClearScrollAsync(ClearScrollRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ClearScrollRequestDescriptor, ClearScrollResponse, ClearScrollRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClearScrollResponse> ClearScrollAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new ClearScrollRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<ClearScrollRequestDescriptor, ClearScrollResponse, ClearScrollRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Clear a scrolling search.
	/// Clear the search context and results for a scrolling search.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/clear-scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClearScrollResponse> ClearScrollAsync(Action<ClearScrollRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ClearScrollRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ClearScrollRequestDescriptor, ClearScrollResponse, ClearScrollRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClosePointInTimeResponse ClosePointInTime(ClosePointInTimeRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ClosePointInTimeRequest, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClosePointInTimeResponse> ClosePointInTimeAsync(ClosePointInTimeRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ClosePointInTimeRequest, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClosePointInTimeResponse ClosePointInTime(ClosePointInTimeRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ClosePointInTimeRequestDescriptor, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClosePointInTimeResponse ClosePointInTime()
	{
		var descriptor = new ClosePointInTimeRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<ClosePointInTimeRequestDescriptor, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ClosePointInTimeResponse ClosePointInTime(Action<ClosePointInTimeRequestDescriptor> configureRequest)
	{
		var descriptor = new ClosePointInTimeRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ClosePointInTimeRequestDescriptor, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClosePointInTimeResponse> ClosePointInTimeAsync(ClosePointInTimeRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ClosePointInTimeRequestDescriptor, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClosePointInTimeResponse> ClosePointInTimeAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new ClosePointInTimeRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<ClosePointInTimeRequestDescriptor, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Close a point in time.
	/// A point in time must be opened explicitly before being used in search requests.
	/// The <c>keep_alive</c> parameter tells Elasticsearch how long it should persist.
	/// A point in time is automatically closed when the <c>keep_alive</c> period has elapsed.
	/// However, keeping points in time has a cost; close them as soon as they are no longer required for search requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ClosePointInTimeResponse> ClosePointInTimeAsync(Action<ClosePointInTimeRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ClosePointInTimeRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ClosePointInTimeRequestDescriptor, ClosePointInTimeResponse, ClosePointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count(CountRequest request)
	{
		request.BeforeRequest();
		return DoRequest<CountRequest, CountResponse, CountRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync(CountRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<CountRequest, CountResponse, CountRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count<TDocument>(CountRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new CountRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<CountRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new CountRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count<TDocument>()
	{
		var descriptor = new CountRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count<TDocument>(Action<CountRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new CountRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count(CountRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new CountRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count(Elastic.Clients.Elasticsearch.Indices? indices, Action<CountRequestDescriptor> configureRequest)
	{
		var descriptor = new CountRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count()
	{
		var descriptor = new CountRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CountResponse Count(Action<CountRequestDescriptor> configureRequest)
	{
		var descriptor = new CountRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync<TDocument>(CountRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<CountRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync<TDocument>(Action<CountRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor<TDocument>, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync(CountRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync(Elastic.Clients.Elasticsearch.Indices? indices, Action<CountRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Count search results.
	/// Get the number of documents matching a query.
	/// </para>
	/// <para>
	/// The query can be provided either by using a simple query string as a parameter, or by defining Query DSL within the request body.
	/// The query is optional. When no query is provided, the API uses <c>match_all</c> to count all the documents.
	/// </para>
	/// <para>
	/// The count API supports multi-target syntax. You can run a single count API search across multiple data streams and indices.
	/// </para>
	/// <para>
	/// The operation is broadcast across all shards.
	/// For each shard ID group, a replica is chosen and the search is run against it.
	/// This means that replicas increase the scalability of the count.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-count.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CountResponse> CountAsync(Action<CountRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CountRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CountRequestDescriptor, CountResponse, CountRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(CreateRequest<TDocument> request)
	{
		request.BeforeRequest();
		return DoRequest<CreateRequest<TDocument>, CreateResponse, CreateRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(CreateRequest<TDocument> request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<CreateRequest<TDocument>, CreateResponse, CreateRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(CreateRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index, id);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<CreateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document, Action<CreateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<CreateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual CreateResponse Create<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<CreateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(CreateRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<CreateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, Action<CreateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<CreateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create a new document in the index.
	/// </para>
	/// <para>
	/// You can index a new JSON document with the <c>/&lt;target>/_doc/</c> or <c>/&lt;target>/_create/&lt;_id></c> APIs
	/// Using <c>_create</c> guarantees that the document is indexed only if it does not already exist.
	/// It returns a 409 response when a document with a same ID already exists in the index.
	/// To update an existing document, you must use the <c>/&lt;target>/_doc/</c> API.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add a document using the <c>PUT /&lt;target>/_create/&lt;_id></c> or <c>POST /&lt;target>/_create/&lt;_id></c> request formats, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<CreateResponse> CreateAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<CreateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new CreateRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<CreateRequestDescriptor<TDocument>, CreateResponse, CreateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete(DeleteRequest request)
	{
		request.BeforeRequest();
		return DoRequest<DeleteRequest, DeleteResponse, DeleteRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync(DeleteRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<DeleteRequest, DeleteResponse, DeleteRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(DeleteRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(TDocument document)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(TDocument document, Action<DeleteRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<DeleteRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete(DeleteRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new DeleteRequestDescriptor(index, id);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteResponse Delete(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor> configureRequest)
	{
		var descriptor = new DeleteRequestDescriptor(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteRequestDescriptor, DeleteResponse, DeleteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(DeleteRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(TDocument document, Action<DeleteRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<DeleteRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor<TDocument>, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync(DeleteRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a document.
	/// </para>
	/// <para>
	/// Remove a JSON document from the specified index.
	/// </para>
	/// <para>
	/// NOTE: You cannot send deletion requests directly to a data stream.
	/// To delete a document in a data stream, you must target the backing index containing the document.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Delete operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each document indexed is versioned.
	/// When deleting a document, the version can be specified to make sure the relevant document you are trying to delete is actually being deleted and it has not changed in the meantime.
	/// Every write operation run on a document, deletes included, causes its version to be incremented.
	/// The version number of a deleted document remains available for a short time after deletion to allow for control of concurrent operations.
	/// The length of time for which a deleted document's version remains available is determined by the <c>index.gc_deletes</c> index setting.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to delete a document.
	/// </para>
	/// <para>
	/// If the <c>_routing</c> mapping is set to <c>required</c> and no routing value is specified, the delete API throws a <c>RoutingMissingException</c> and rejects the request.
	/// </para>
	/// <para>
	/// For example:
	/// </para>
	/// <code>
	/// DELETE /my-index-000001/_doc/1?routing=shard-1
	/// </code>
	/// <para>
	/// This request deletes the document with ID 1, but it is routed based on the user.
	/// The document is not deleted if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The delete operation gets hashed into a specific shard ID.
	/// It then gets redirected into the primary shard within that ID group and replicated (if needed) to shard replicas within that ID group.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteResponse> DeleteAsync(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<DeleteRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteRequestDescriptor(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteRequestDescriptor, DeleteResponse, DeleteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery(DeleteByQueryRequest request)
	{
		request.BeforeRequest();
		return DoRequest<DeleteByQueryRequest, DeleteByQueryResponse, DeleteByQueryRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync(DeleteByQueryRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequest, DeleteByQueryResponse, DeleteByQueryRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery<TDocument>(DeleteByQueryRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery<TDocument>(Elastic.Clients.Elasticsearch.Indices indices)
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Action<DeleteByQueryRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery<TDocument>()
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery<TDocument>(Action<DeleteByQueryRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery(DeleteByQueryRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery(Elastic.Clients.Elasticsearch.Indices indices)
	{
		var descriptor = new DeleteByQueryRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryResponse DeleteByQuery(Elastic.Clients.Elasticsearch.Indices indices, Action<DeleteByQueryRequestDescriptor> configureRequest)
	{
		var descriptor = new DeleteByQueryRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRequestDescriptor, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync<TDocument>(DeleteByQueryRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Action<DeleteByQueryRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync<TDocument>(Action<DeleteByQueryRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor<TDocument>, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync(DeleteByQueryRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync(Elastic.Clients.Elasticsearch.Indices indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete documents.
	/// </para>
	/// <para>
	/// Deletes documents that match the specified query.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>delete</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// When you submit a delete by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and deletes matching documents using internal versioning.
	/// If a document changes between the time that the snapshot is taken and the delete operation is processed, it results in a version conflict and the delete operation fails.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be deleted using delete by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing a delete by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents to delete.
	/// A bulk delete request is performed for each batch of matching documents.
	/// If a search or bulk request is rejected, the requests are retried up to 10 times, with exponential back off.
	/// If the maximum retry limit is reached, processing halts and all failed requests are returned in the response.
	/// Any delete requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts the operation could attempt to delete more documents from the source than <c>max_docs</c> until it has successfully deleted <c>max_docs documents</c>, or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// <strong>Throttling delete requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which delete by query issues batches of delete operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to disable throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single <c>_bulk</c> request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Delete by query supports sliced scroll to parallelize the delete process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> lets Elasticsearch choose the number of slices to use.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// Adding slices to the delete by query operation creates sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with slices only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c> each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the earlier point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being deleted.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many <c>slices</c> hurts performance. Setting <c>slices</c> higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Delete performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or delete performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Cancel a delete by query operation</strong>
	/// </para>
	/// <para>
	/// Any delete by query can be canceled using the task cancel API. For example:
	/// </para>
	/// <code>
	/// POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel
	/// </code>
	/// <para>
	/// The task ID can be found by using the get tasks API.
	/// </para>
	/// <para>
	/// Cancellation should happen quickly but might take a few seconds.
	/// The get task status API will continue to list the delete by query task until this task checks that it has been cancelled and terminates itself.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryResponse> DeleteByQueryAsync(Elastic.Clients.Elasticsearch.Indices indices, Action<DeleteByQueryRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRequestDescriptor, DeleteByQueryResponse, DeleteByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryRethrottleResponse DeleteByQueryRethrottle(DeleteByQueryRethrottleRequest request)
	{
		request.BeforeRequest();
		return DoRequest<DeleteByQueryRethrottleRequest, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryRethrottleResponse> DeleteByQueryRethrottleAsync(DeleteByQueryRethrottleRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRethrottleRequest, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryRethrottleResponse DeleteByQueryRethrottle(DeleteByQueryRethrottleRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRethrottleRequestDescriptor, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryRethrottleResponse DeleteByQueryRethrottle(Elastic.Clients.Elasticsearch.TaskId taskId)
	{
		var descriptor = new DeleteByQueryRethrottleRequestDescriptor(taskId);
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRethrottleRequestDescriptor, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteByQueryRethrottleResponse DeleteByQueryRethrottle(Elastic.Clients.Elasticsearch.TaskId taskId, Action<DeleteByQueryRethrottleRequestDescriptor> configureRequest)
	{
		var descriptor = new DeleteByQueryRethrottleRequestDescriptor(taskId);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteByQueryRethrottleRequestDescriptor, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryRethrottleResponse> DeleteByQueryRethrottleAsync(DeleteByQueryRethrottleRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRethrottleRequestDescriptor, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryRethrottleResponse> DeleteByQueryRethrottleAsync(Elastic.Clients.Elasticsearch.TaskId taskId, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRethrottleRequestDescriptor(taskId);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRethrottleRequestDescriptor, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a delete by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular delete by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-delete-by-query.html#docs-delete-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteByQueryRethrottleResponse> DeleteByQueryRethrottleAsync(Elastic.Clients.Elasticsearch.TaskId taskId, Action<DeleteByQueryRethrottleRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteByQueryRethrottleRequestDescriptor(taskId);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteByQueryRethrottleRequestDescriptor, DeleteByQueryRethrottleResponse, DeleteByQueryRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteScriptResponse DeleteScript(DeleteScriptRequest request)
	{
		request.BeforeRequest();
		return DoRequest<DeleteScriptRequest, DeleteScriptResponse, DeleteScriptRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteScriptResponse> DeleteScriptAsync(DeleteScriptRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<DeleteScriptRequest, DeleteScriptResponse, DeleteScriptRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteScriptResponse DeleteScript<TDocument>(DeleteScriptRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<DeleteScriptRequestDescriptor<TDocument>, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteScriptResponse DeleteScript<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new DeleteScriptRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<DeleteScriptRequestDescriptor<TDocument>, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteScriptResponse DeleteScript<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<DeleteScriptRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new DeleteScriptRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteScriptRequestDescriptor<TDocument>, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteScriptResponse DeleteScript(DeleteScriptRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<DeleteScriptRequestDescriptor, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteScriptResponse DeleteScript(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new DeleteScriptRequestDescriptor(id);
		descriptor.BeforeRequest();
		return DoRequest<DeleteScriptRequestDescriptor, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual DeleteScriptResponse DeleteScript(Elastic.Clients.Elasticsearch.Id id, Action<DeleteScriptRequestDescriptor> configureRequest)
	{
		var descriptor = new DeleteScriptRequestDescriptor(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<DeleteScriptRequestDescriptor, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteScriptResponse> DeleteScriptAsync<TDocument>(DeleteScriptRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteScriptRequestDescriptor<TDocument>, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteScriptResponse> DeleteScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteScriptRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteScriptRequestDescriptor<TDocument>, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteScriptResponse> DeleteScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<DeleteScriptRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteScriptRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteScriptRequestDescriptor<TDocument>, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteScriptResponse> DeleteScriptAsync(DeleteScriptRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteScriptRequestDescriptor, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteScriptResponse> DeleteScriptAsync(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteScriptRequestDescriptor(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteScriptRequestDescriptor, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Delete a script or search template.
	/// Deletes a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/delete-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<DeleteScriptResponse> DeleteScriptAsync(Elastic.Clients.Elasticsearch.Id id, Action<DeleteScriptRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new DeleteScriptRequestDescriptor(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<DeleteScriptRequestDescriptor, DeleteScriptResponse, DeleteScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists(ExistsRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ExistsRequest, ExistsResponse, ExistsRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync(ExistsRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ExistsRequest, ExistsResponse, ExistsRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(ExistsRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(TDocument document)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(TDocument document, Action<ExistsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<ExistsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists(ExistsRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsRequestDescriptor(index, id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsResponse Exists(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor> configureRequest)
	{
		var descriptor = new ExistsRequestDescriptor(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsRequestDescriptor, ExistsResponse, ExistsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(ExistsRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(TDocument document, Action<ExistsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<ExistsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor<TDocument>, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync(ExistsRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check a document.
	/// </para>
	/// <para>
	/// Verify that a document exists.
	/// For example, check to see if a document with the <c>_id</c> 0 exists:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_doc/0
	/// </code>
	/// <para>
	/// If the document exists, the API returns a status code of <c>200 - OK</c>.
	/// If the document doesn’t exist, the API returns <c>404 - Not Found</c>.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to check the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsResponse> ExistsAsync(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsRequestDescriptor(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsRequestDescriptor, ExistsResponse, ExistsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource(ExistsSourceRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ExistsSourceRequest, ExistsSourceResponse, ExistsSourceRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync(ExistsSourceRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequest, ExistsSourceResponse, ExistsSourceRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(ExistsSourceRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(TDocument document)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(TDocument document, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource(ExistsSourceRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExistsSourceRequestDescriptor(index, id);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExistsSourceResponse ExistsSource(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor> configureRequest)
	{
		var descriptor = new ExistsSourceRequestDescriptor(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExistsSourceRequestDescriptor, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(ExistsSourceRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(TDocument document, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor<TDocument>, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync(ExistsSourceRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Check for a document source.
	/// </para>
	/// <para>
	/// Check whether a document source exists in an index.
	/// For example:
	/// </para>
	/// <code>
	/// HEAD my-index-000001/_source/1
	/// </code>
	/// <para>
	/// A document's source is not available if it is disabled in the mapping.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExistsSourceResponse> ExistsSourceAsync(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExistsSourceRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExistsSourceRequestDescriptor(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExistsSourceRequestDescriptor, ExistsSourceResponse, ExistsSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(ExplainRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ExplainRequest, ExplainResponse<TDocument>, ExplainRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(ExplainRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ExplainRequest, ExplainResponse<TDocument>, ExplainRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(ExplainRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExplainRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(TDocument document)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(TDocument document, Action<ExplainRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<ExplainRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<ExplainRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ExplainResponse<TDocument> Explain<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<ExplainRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(ExplainRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<ExplainRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(TDocument document, Action<ExplainRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<ExplainRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<ExplainRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Explain a document match result.
	/// Get information about why a specific document matches, or doesn't match, a query.
	/// It computes a score explanation for a query and a specific document.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-explain.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ExplainResponse<TDocument>> ExplainAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<ExplainRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ExplainRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ExplainRequestDescriptor<TDocument>, ExplainResponse<TDocument>, ExplainRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps(FieldCapsRequest request)
	{
		request.BeforeRequest();
		return DoRequest<FieldCapsRequest, FieldCapsResponse, FieldCapsRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync(FieldCapsRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<FieldCapsRequest, FieldCapsResponse, FieldCapsRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps<TDocument>(FieldCapsRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<FieldCapsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps<TDocument>()
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps<TDocument>(Action<FieldCapsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps(FieldCapsRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new FieldCapsRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps(Elastic.Clients.Elasticsearch.Indices? indices, Action<FieldCapsRequestDescriptor> configureRequest)
	{
		var descriptor = new FieldCapsRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps()
	{
		var descriptor = new FieldCapsRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual FieldCapsResponse FieldCaps(Action<FieldCapsRequestDescriptor> configureRequest)
	{
		var descriptor = new FieldCapsRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync<TDocument>(FieldCapsRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<FieldCapsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync<TDocument>(Action<FieldCapsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor<TDocument>, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync(FieldCapsRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync(Elastic.Clients.Elasticsearch.Indices? indices, Action<FieldCapsRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the field capabilities.
	/// </para>
	/// <para>
	/// Get information about the capabilities of fields among multiple indices.
	/// </para>
	/// <para>
	/// For data streams, the API returns field capabilities among the stream’s backing indices.
	/// It returns runtime fields like any other field.
	/// For example, a runtime field with a type of keyword is returned the same as any other field that belongs to the <c>keyword</c> family.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-field-caps.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<FieldCapsResponse> FieldCapsAsync(Action<FieldCapsRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new FieldCapsRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<FieldCapsRequestDescriptor, FieldCapsResponse, FieldCapsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(GetRequest request)
	{
		request.BeforeRequest();
		return DoRequest<GetRequest, GetResponse<TDocument>, GetRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(GetRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<GetRequest, GetResponse<TDocument>, GetRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(GetRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<GetRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(TDocument document)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(TDocument document, Action<GetRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<GetRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<GetRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetResponse<TDocument> Get<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<GetRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(GetRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<GetRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(TDocument document, Action<GetRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<GetRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<GetRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document by its ID.
	/// </para>
	/// <para>
	/// Get a document and its source or stored fields from an index.
	/// </para>
	/// <para>
	/// By default, this API is realtime and is not affected by the refresh rate of the index (when data will become visible for search).
	/// In the case where stored fields are requested with the <c>stored_fields</c> parameter and the document has been updated but is not yet refreshed, the API will have to parse and analyze the source to extract the stored fields.
	/// To turn off realtime behavior, set the <c>realtime</c> parameter to false.
	/// </para>
	/// <para>
	/// <strong>Source filtering</strong>
	/// </para>
	/// <para>
	/// By default, the API returns the contents of the <c>_source</c> field unless you have used the <c>stored_fields</c> parameter or the <c>_source</c> field is turned off.
	/// You can turn off <c>_source</c> retrieval by using the <c>_source</c> parameter:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=false
	/// </code>
	/// <para>
	/// If you only need one or two fields from the <c>_source</c>, use the <c>_source_includes</c> or <c>_source_excludes</c> parameters to include or filter out particular fields.
	/// This can be helpful with large documents where partial retrieval can save on network overhead
	/// Both parameters take a comma separated list of fields or wildcard expressions.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para>
	/// If you only want to specify includes, you can use a shorter notation:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/0?_source=*.id
	/// </code>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// If routing is used during indexing, the routing value also needs to be specified to retrieve a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_doc/2?routing=user1
	/// </code>
	/// <para>
	/// This request gets the document with ID 2, but it is routed based on the user.
	/// The document is not fetched if the correct routing is not specified.
	/// </para>
	/// <para>
	/// <strong>Distributed</strong>
	/// </para>
	/// <para>
	/// The GET operation is hashed into a specific shard ID.
	/// It is then redirected to one of the replicas within that shard ID and returns the result.
	/// The replicas are the primary shard and its replicas within that shard ID group.
	/// This means that the more replicas you have, the better your GET scaling will be.
	/// </para>
	/// <para>
	/// <strong>Versioning support</strong>
	/// </para>
	/// <para>
	/// You can use the <c>version</c> parameter to retrieve the document only if its current version is equal to the specified one.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch has marked the old document as deleted and added an entirely new document.
	/// The old version of the document doesn't disappear immediately, although you won't be able to access it.
	/// Elasticsearch cleans up deleted documents in the background as you continue to index more data.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetResponse<TDocument>> GetAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<GetRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetRequestDescriptor<TDocument>, GetResponse<TDocument>, GetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptResponse GetScript(GetScriptRequest request)
	{
		request.BeforeRequest();
		return DoRequest<GetScriptRequest, GetScriptResponse, GetScriptRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptResponse> GetScriptAsync(GetScriptRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<GetScriptRequest, GetScriptResponse, GetScriptRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptResponse GetScript<TDocument>(GetScriptRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<GetScriptRequestDescriptor<TDocument>, GetScriptResponse, GetScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptResponse GetScript<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetScriptRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<GetScriptRequestDescriptor<TDocument>, GetScriptResponse, GetScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptResponse GetScript<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<GetScriptRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetScriptRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetScriptRequestDescriptor<TDocument>, GetScriptResponse, GetScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptResponse GetScript(GetScriptRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<GetScriptRequestDescriptor, GetScriptResponse, GetScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptResponse GetScript(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetScriptRequestDescriptor(id);
		descriptor.BeforeRequest();
		return DoRequest<GetScriptRequestDescriptor, GetScriptResponse, GetScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptResponse GetScript(Elastic.Clients.Elasticsearch.Id id, Action<GetScriptRequestDescriptor> configureRequest)
	{
		var descriptor = new GetScriptRequestDescriptor(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetScriptRequestDescriptor, GetScriptResponse, GetScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptResponse> GetScriptAsync<TDocument>(GetScriptRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptRequestDescriptor<TDocument>, GetScriptResponse, GetScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptResponse> GetScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptRequestDescriptor<TDocument>, GetScriptResponse, GetScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptResponse> GetScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<GetScriptRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptRequestDescriptor<TDocument>, GetScriptResponse, GetScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptResponse> GetScriptAsync(GetScriptRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptRequestDescriptor, GetScriptResponse, GetScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptResponse> GetScriptAsync(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptRequestDescriptor(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptRequestDescriptor, GetScriptResponse, GetScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a script or search template.
	/// Retrieves a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptResponse> GetScriptAsync(Elastic.Clients.Elasticsearch.Id id, Action<GetScriptRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptRequestDescriptor(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptRequestDescriptor, GetScriptResponse, GetScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptContextResponse GetScriptContext(GetScriptContextRequest request)
	{
		request.BeforeRequest();
		return DoRequest<GetScriptContextRequest, GetScriptContextResponse, GetScriptContextRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptContextResponse> GetScriptContextAsync(GetScriptContextRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<GetScriptContextRequest, GetScriptContextResponse, GetScriptContextRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptContextResponse GetScriptContext(GetScriptContextRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<GetScriptContextRequestDescriptor, GetScriptContextResponse, GetScriptContextRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptContextResponse GetScriptContext()
	{
		var descriptor = new GetScriptContextRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<GetScriptContextRequestDescriptor, GetScriptContextResponse, GetScriptContextRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptContextResponse GetScriptContext(Action<GetScriptContextRequestDescriptor> configureRequest)
	{
		var descriptor = new GetScriptContextRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetScriptContextRequestDescriptor, GetScriptContextResponse, GetScriptContextRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptContextResponse> GetScriptContextAsync(GetScriptContextRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptContextRequestDescriptor, GetScriptContextResponse, GetScriptContextRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptContextResponse> GetScriptContextAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptContextRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptContextRequestDescriptor, GetScriptContextResponse, GetScriptContextRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script contexts.
	/// </para>
	/// <para>
	/// Get a list of supported script contexts and their methods.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-contexts-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptContextResponse> GetScriptContextAsync(Action<GetScriptContextRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptContextRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptContextRequestDescriptor, GetScriptContextResponse, GetScriptContextRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptLanguagesResponse GetScriptLanguages(GetScriptLanguagesRequest request)
	{
		request.BeforeRequest();
		return DoRequest<GetScriptLanguagesRequest, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptLanguagesResponse> GetScriptLanguagesAsync(GetScriptLanguagesRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<GetScriptLanguagesRequest, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptLanguagesResponse GetScriptLanguages(GetScriptLanguagesRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<GetScriptLanguagesRequestDescriptor, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptLanguagesResponse GetScriptLanguages()
	{
		var descriptor = new GetScriptLanguagesRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<GetScriptLanguagesRequestDescriptor, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetScriptLanguagesResponse GetScriptLanguages(Action<GetScriptLanguagesRequestDescriptor> configureRequest)
	{
		var descriptor = new GetScriptLanguagesRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetScriptLanguagesRequestDescriptor, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptLanguagesResponse> GetScriptLanguagesAsync(GetScriptLanguagesRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptLanguagesRequestDescriptor, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptLanguagesResponse> GetScriptLanguagesAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptLanguagesRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptLanguagesRequestDescriptor, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get script languages.
	/// </para>
	/// <para>
	/// Get a list of available script types, languages, and contexts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/get-script-languages-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetScriptLanguagesResponse> GetScriptLanguagesAsync(Action<GetScriptLanguagesRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetScriptLanguagesRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetScriptLanguagesRequestDescriptor, GetScriptLanguagesResponse, GetScriptLanguagesRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(GetSourceRequest request)
	{
		request.BeforeRequest();
		return DoRequest<GetSourceRequest, GetSourceResponse<TDocument>, GetSourceRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(GetSourceRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<GetSourceRequest, GetSourceResponse<TDocument>, GetSourceRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(GetSourceRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<GetSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(TDocument document)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(TDocument document, Action<GetSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<GetSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<GetSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual GetSourceResponse<TDocument> GetSource<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<GetSourceRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(GetSourceRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<GetSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(TDocument document, Action<GetSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<GetSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<GetSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get a document's source.
	/// </para>
	/// <para>
	/// Get the source of a document.
	/// For example:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1
	/// </code>
	/// <para>
	/// You can use the source filtering parameters to control which parts of the <c>_source</c> are returned:
	/// </para>
	/// <code>
	/// GET my-index-000001/_source/1/?_source_includes=*.id&amp;_source_excludes=entities
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<GetSourceResponse<TDocument>> GetSourceAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<GetSourceRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new GetSourceRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<GetSourceRequestDescriptor<TDocument>, GetSourceResponse<TDocument>, GetSourceRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual HealthReportResponse HealthReport(HealthReportRequest request)
	{
		request.BeforeRequest();
		return DoRequest<HealthReportRequest, HealthReportResponse, HealthReportRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<HealthReportResponse> HealthReportAsync(HealthReportRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<HealthReportRequest, HealthReportResponse, HealthReportRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual HealthReportResponse HealthReport(HealthReportRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual HealthReportResponse HealthReport(IReadOnlyCollection<string>? feature)
	{
		var descriptor = new HealthReportRequestDescriptor(feature);
		descriptor.BeforeRequest();
		return DoRequest<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual HealthReportResponse HealthReport(IReadOnlyCollection<string>? feature, Action<HealthReportRequestDescriptor> configureRequest)
	{
		var descriptor = new HealthReportRequestDescriptor(feature);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual HealthReportResponse HealthReport()
	{
		var descriptor = new HealthReportRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual HealthReportResponse HealthReport(Action<HealthReportRequestDescriptor> configureRequest)
	{
		var descriptor = new HealthReportRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<HealthReportResponse> HealthReportAsync(HealthReportRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<HealthReportResponse> HealthReportAsync(IReadOnlyCollection<string>? feature, CancellationToken cancellationToken = default)
	{
		var descriptor = new HealthReportRequestDescriptor(feature);
		descriptor.BeforeRequest();
		return DoRequestAsync<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<HealthReportResponse> HealthReportAsync(IReadOnlyCollection<string>? feature, Action<HealthReportRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new HealthReportRequestDescriptor(feature);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<HealthReportResponse> HealthReportAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new HealthReportRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the cluster health.
	/// Get a report with the health status of an Elasticsearch cluster.
	/// The report contains a list of indicators that compose Elasticsearch functionality.
	/// </para>
	/// <para>
	/// Each indicator has a health status of: green, unknown, yellow or red.
	/// The indicator will provide an explanation and metadata describing the reason for its current health status.
	/// </para>
	/// <para>
	/// The cluster’s status is controlled by the worst indicator status.
	/// </para>
	/// <para>
	/// In the event that an indicator’s status is non-green, a list of impacts may be present in the indicator result which detail the functionalities that are negatively affected by the health issue.
	/// Each impact carries with it a severity level, an area of the system that is affected, and a simple description of the impact on the system.
	/// </para>
	/// <para>
	/// Some health indicators can determine the root cause of a health problem and prescribe a set of steps that can be performed in order to improve the health of the system.
	/// The root cause and remediation steps are encapsulated in a diagnosis.
	/// A diagnosis contains a cause detailing a root cause analysis, an action containing a brief description of the steps to take to fix the problem, the list of affected resources (if applicable), and a detailed step-by-step troubleshooting guide to fix the diagnosed problem.
	/// </para>
	/// <para>
	/// NOTE: The health indicators perform root cause analysis of non-green health statuses. This can be computationally expensive when called frequently.
	/// When setting up automated polling of the API for health status, set verbose to false to disable the more expensive analysis logic.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/health-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<HealthReportResponse> HealthReportAsync(Action<HealthReportRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new HealthReportRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<HealthReportRequestDescriptor, HealthReportResponse, HealthReportRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(IndexRequest<TDocument> request)
	{
		request.BeforeRequest();
		return DoRequest<IndexRequest<TDocument>, IndexResponse, IndexRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(IndexRequest<TDocument> request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<IndexRequest<TDocument>, IndexResponse, IndexRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(IndexRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index, id);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id, Action<IndexRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document, Action<IndexRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<IndexRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual IndexResponse Index<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id, Action<IndexRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(IndexRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id, Action<IndexRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, Action<IndexRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<IndexRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a document in an index.
	/// </para>
	/// <para>
	/// Add a JSON document to the specified data stream or index and make it searchable.
	/// If the target is an index and the document already exists, the request updates the document and increments its version.
	/// </para>
	/// <para>
	/// NOTE: You cannot use this API to send update requests for existing documents in a data stream.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// To add or overwrite a document using the <c>PUT /&lt;target>/_doc/&lt;_id></c> request format, you must have the <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To add a document using the <c>POST /&lt;target>/_doc/</c> request format, you must have the <c>create_doc</c>, <c>create</c>, <c>index</c>, or <c>write</c> index privilege.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with this API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// NOTE: Replica shards might not all be started when an indexing operation returns successfully.
	/// By default, only the primary is required. Set <c>wait_for_active_shards</c> to change this default behavior.
	/// </para>
	/// <para>
	/// <strong>Automatically create data streams and indices</strong>
	/// </para>
	/// <para>
	/// If the request's target doesn't exist and matches an index template with a <c>data_stream</c> definition, the index operation automatically creates the data stream.
	/// </para>
	/// <para>
	/// If the target doesn't exist and doesn't match a data stream template, the operation automatically creates the index and applies any matching index templates.
	/// </para>
	/// <para>
	/// NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.
	/// </para>
	/// <para>
	/// If no mapping exists, the index operation creates a dynamic mapping.
	/// By default, new fields and objects are automatically added to the mapping if needed.
	/// </para>
	/// <para>
	/// Automatic index creation is controlled by the <c>action.auto_create_index</c> setting.
	/// If it is <c>true</c>, any index can be created automatically.
	/// You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to <c>false</c> to turn off automatic index creation entirely.
	/// Specify a comma-separated list of patterns you want to allow or prefix each pattern with <c>+</c> or <c>-</c> to indicate whether it should be allowed or blocked.
	/// When a list is specified, the default behaviour is to disallow.
	/// </para>
	/// <para>
	/// NOTE: The <c>action.auto_create_index</c> setting affects the automatic creation of indices only.
	/// It does not affect the creation of data streams.
	/// </para>
	/// <para>
	/// <strong>Optimistic concurrency control</strong>
	/// </para>
	/// <para>
	/// Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the <c>if_seq_no</c> and <c>if_primary_term</c> parameters.
	/// If a mismatch is detected, the operation will result in a <c>VersionConflictException</c> and a status code of <c>409</c>.
	/// </para>
	/// <para>
	/// <strong>Routing</strong>
	/// </para>
	/// <para>
	/// By default, shard placement — or routing — is controlled by using a hash of the document's ID value.
	/// For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the <c>routing</c> parameter.
	/// </para>
	/// <para>
	/// When setting up explicit mapping, you can also use the <c>_routing</c> field to direct the index operation to extract the routing value from the document itself.
	/// This does come at the (very minimal) cost of an additional document parsing pass.
	/// If the <c>_routing</c> mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.
	/// </para>
	/// <para>
	/// NOTE: Data streams do not support custom routing unless they were created with the <c>allow_custom_routing</c> setting enabled in the template.
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// ** Distributed**
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.
	/// After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.
	/// </para>
	/// <para>
	/// <strong>Active shards</strong>
	/// </para>
	/// <para>
	/// To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.
	/// If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.
	/// By default, write operations only wait for the primary shards to be active before proceeding (that is to say <c>wait_for_active_shards</c> is <c>1</c>).
	/// This default can be overridden in the index settings dynamically by setting <c>index.write.wait_for_active_shards</c>.
	/// To alter this behavior per operation, use the <c>wait_for_active_shards request</c> parameter.
	/// </para>
	/// <para>
	/// Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is <c>number_of_replicas</c>+1).
	/// Specifying a negative value or a number greater than the number of shard copies will throw an error.
	/// </para>
	/// <para>
	/// For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).
	/// If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.
	/// This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.
	/// If <c>wait_for_active_shards</c> is set on the request to <c>3</c> (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.
	/// This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.
	/// However, if you set <c>wait_for_active_shards</c> to <c>all</c> (or to <c>4</c>, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.
	/// The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.
	/// </para>
	/// <para>
	/// It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.
	/// After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.
	/// The <c>_shards</c> section of the API response reveals the number of shard copies on which replication succeeded and failed.
	/// </para>
	/// <para>
	/// <strong>No operation (noop) updates</strong>
	/// </para>
	/// <para>
	/// When updating a document by using this API, a new version of the document is always created even if the document hasn't changed.
	/// If this isn't acceptable use the <c>_update</c> API with <c>detect_noop</c> set to <c>true</c>.
	/// The <c>detect_noop</c> option isn't available on this API because it doesn’t fetch the old source and isn't able to compare it against the new source.
	/// </para>
	/// <para>
	/// There isn't a definitive rule for when noop updates aren't acceptable.
	/// It's a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.
	/// </para>
	/// <para>
	/// <strong>Versioning</strong>
	/// </para>
	/// <para>
	/// Each indexed document is given a version number.
	/// By default, internal versioning is used that starts at 1 and increments with each update, deletes included.
	/// Optionally, the version number can be set to an external value (for example, if maintained in a database).
	/// To enable this functionality, <c>version_type</c> should be set to <c>external</c>.
	/// The value provided must be a numeric, long value greater than or equal to 0, and less than around <c>9.2e+18</c>.
	/// </para>
	/// <para>
	/// NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.
	/// If no version is provided, the operation runs without any version checks.
	/// </para>
	/// <para>
	/// When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.
	/// If true, the document will be indexed and the new version number used.
	/// If the value provided is less than or equal to the stored document's version number, a version conflict will occur and the index operation will fail. For example:
	/// </para>
	/// <code>
	/// PUT my-index-000001/_doc/1?version=2&amp;version_type=external
	/// {
	///   "user": {
	///     "id": "elkbee"
	///   }
	/// }
	/// 
	/// In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.
	/// If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).
	/// 
	/// A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.
	/// Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-index_.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<IndexResponse> IndexAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id, Action<IndexRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new IndexRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<IndexRequestDescriptor<TDocument>, IndexResponse, IndexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual InfoResponse Info(InfoRequest request)
	{
		request.BeforeRequest();
		return DoRequest<InfoRequest, InfoResponse, InfoRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<InfoResponse> InfoAsync(InfoRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<InfoRequest, InfoResponse, InfoRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual InfoResponse Info(InfoRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<InfoRequestDescriptor, InfoResponse, InfoRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual InfoResponse Info()
	{
		var descriptor = new InfoRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<InfoRequestDescriptor, InfoResponse, InfoRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual InfoResponse Info(Action<InfoRequestDescriptor> configureRequest)
	{
		var descriptor = new InfoRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<InfoRequestDescriptor, InfoResponse, InfoRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<InfoResponse> InfoAsync(InfoRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<InfoRequestDescriptor, InfoResponse, InfoRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<InfoResponse> InfoAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new InfoRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<InfoRequestDescriptor, InfoResponse, InfoRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get cluster info.
	/// Get basic build, version, and cluster information.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/rest-api-root.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<InfoResponse> InfoAsync(Action<InfoRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new InfoRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<InfoRequestDescriptor, InfoResponse, InfoRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors(MultiTermVectorsRequest request)
	{
		request.BeforeRequest();
		return DoRequest<MultiTermVectorsRequest, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync(MultiTermVectorsRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequest, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors<TDocument>(MultiTermVectorsRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, Action<MultiTermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors<TDocument>()
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors<TDocument>(Action<MultiTermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors(MultiTermVectorsRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors(Elastic.Clients.Elasticsearch.IndexName? index)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor(index);
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors(Elastic.Clients.Elasticsearch.IndexName? index, Action<MultiTermVectorsRequestDescriptor> configureRequest)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors()
	{
		var descriptor = new MultiTermVectorsRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiTermVectorsResponse Mtermvectors(Action<MultiTermVectorsRequestDescriptor> configureRequest)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync<TDocument>(MultiTermVectorsRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, Action<MultiTermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync<TDocument>(Action<MultiTermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor<TDocument>, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync(MultiTermVectorsRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync(Elastic.Clients.Elasticsearch.IndexName? index, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync(Elastic.Clients.Elasticsearch.IndexName? index, Action<MultiTermVectorsRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple term vectors.
	/// </para>
	/// <para>
	/// Get multiple term vectors with a single request.
	/// You can specify existing documents by index and ID or provide artificial documents in the body of the request.
	/// You can specify the index in the request body or request URI.
	/// The response contains a <c>docs</c> array with all the fetched termvectors.
	/// Each element has the structure provided by the termvectors API.
	/// </para>
	/// <para>
	/// <strong>Artificial documents</strong>
	/// </para>
	/// <para>
	/// You can also use <c>mtermvectors</c> to generate term vectors for artificial documents provided in the body of the request.
	/// The mapping used is determined by the specified <c>_index</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiTermVectorsResponse> MtermvectorsAsync(Action<MultiTermVectorsRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiTermVectorsRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiTermVectorsRequestDescriptor, MultiTermVectorsResponse, MultiTermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiGetResponse<TDocument> MultiGet<TDocument>(MultiGetRequest request)
	{
		request.BeforeRequest();
		return DoRequest<MultiGetRequest, MultiGetResponse<TDocument>, MultiGetRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiGetResponse<TDocument>> MultiGetAsync<TDocument>(MultiGetRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<MultiGetRequest, MultiGetResponse<TDocument>, MultiGetRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiGetResponse<TDocument> MultiGet<TDocument>(MultiGetRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiGetResponse<TDocument> MultiGet<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index)
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequest<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiGetResponse<TDocument> MultiGet<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, Action<MultiGetRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiGetResponse<TDocument> MultiGet<TDocument>()
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiGetResponse<TDocument> MultiGet<TDocument>(Action<MultiGetRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiGetResponse<TDocument>> MultiGetAsync<TDocument>(MultiGetRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiGetResponse<TDocument>> MultiGetAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiGetResponse<TDocument>> MultiGetAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName? index, Action<MultiGetRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiGetResponse<TDocument>> MultiGetAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get multiple documents.
	/// </para>
	/// <para>
	/// Get multiple JSON documents by ID from one or more indices.
	/// If you specify an index in the request URI, you only need to specify the document IDs in the request body.
	/// To ensure fast responses, this multi get (mget) API responds with partial results if one or more shards fail.
	/// </para>
	/// <para>
	/// <strong>Filter source fields</strong>
	/// </para>
	/// <para>
	/// By default, the <c>_source</c> field is returned for every document (if stored).
	/// Use the <c>_source</c> and <c>_source_include</c> or <c>source_exclude</c> attributes to filter what fields are returned for a particular document.
	/// You can include the <c>_source</c>, <c>_source_includes</c>, and <c>_source_excludes</c> query parameters in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para>
	/// <strong>Get stored fields</strong>
	/// </para>
	/// <para>
	/// Use the <c>stored_fields</c> attribute to specify the set of stored fields you want to retrieve.
	/// Any requested fields that are not stored are ignored.
	/// You can include the <c>stored_fields</c> query parameter in the request URI to specify the defaults to use when there are no per-document instructions.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-multi-get.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiGetResponse<TDocument>> MultiGetAsync<TDocument>(Action<MultiGetRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiGetRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiGetRequestDescriptor<TDocument>, MultiGetResponse<TDocument>, MultiGetRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchResponse<TDocument> MultiSearch<TDocument>(MultiSearchRequest request)
	{
		request.BeforeRequest();
		return DoRequest<MultiSearchRequest, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchResponse<TDocument>> MultiSearchAsync<TDocument>(MultiSearchRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<MultiSearchRequest, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchResponse<TDocument> MultiSearch<TDocument>(MultiSearchRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchResponse<TDocument> MultiSearch<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchResponse<TDocument> MultiSearch<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<MultiSearchRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchResponse<TDocument> MultiSearch<TDocument>()
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchResponse<TDocument> MultiSearch<TDocument>(Action<MultiSearchRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchResponse<TDocument>> MultiSearchAsync<TDocument>(MultiSearchRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchResponse<TDocument>> MultiSearchAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchResponse<TDocument>> MultiSearchAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<MultiSearchRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchResponse<TDocument>> MultiSearchAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple searches.
	/// </para>
	/// <para>
	/// The format of the request is similar to the bulk API format and makes use of the newline delimited JSON (NDJSON) format.
	/// The structure is as follows:
	/// </para>
	/// <code>
	/// header\n
	/// body\n
	/// header\n
	/// body\n
	/// </code>
	/// <para>
	/// This structure is specifically optimized to reduce parsing if a specific search ends up redirected to another node.
	/// </para>
	/// <para>
	/// IMPORTANT: The final line of data must end with a newline character <c>\n</c>.
	/// Each newline character may be preceded by a carriage return <c>\r</c>.
	/// When sending requests to this endpoint the <c>Content-Type</c> header should be set to <c>application/x-ndjson</c>.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-multi-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchResponse<TDocument>> MultiSearchAsync<TDocument>(Action<MultiSearchRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchRequestDescriptor<TDocument>, MultiSearchResponse<TDocument>, MultiSearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchTemplateResponse<TDocument> MultiSearchTemplate<TDocument>(MultiSearchTemplateRequest request)
	{
		request.BeforeRequest();
		return DoRequest<MultiSearchTemplateRequest, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchTemplateResponse<TDocument>> MultiSearchTemplateAsync<TDocument>(MultiSearchTemplateRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<MultiSearchTemplateRequest, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchTemplateResponse<TDocument> MultiSearchTemplate<TDocument>(MultiSearchTemplateRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchTemplateResponse<TDocument> MultiSearchTemplate<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchTemplateResponse<TDocument> MultiSearchTemplate<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<MultiSearchTemplateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchTemplateResponse<TDocument> MultiSearchTemplate<TDocument>()
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual MultiSearchTemplateResponse<TDocument> MultiSearchTemplate<TDocument>(Action<MultiSearchTemplateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchTemplateResponse<TDocument>> MultiSearchTemplateAsync<TDocument>(MultiSearchTemplateRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchTemplateResponse<TDocument>> MultiSearchTemplateAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchTemplateResponse<TDocument>> MultiSearchTemplateAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<MultiSearchTemplateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchTemplateResponse<TDocument>> MultiSearchTemplateAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run multiple templated searches.
	/// </para>
	/// <para>
	/// Run multiple templated searches with a single request.
	/// If you are providing a text file or text input to <c>curl</c>, use the <c>--data-binary</c> flag instead of <c>-d</c> to preserve newlines.
	/// For example:
	/// </para>
	/// <code>
	/// $ cat requests
	/// { "index": "my-index" }
	/// { "id": "my-search-template", "params": { "query_string": "hello world", "from": 0, "size": 10 }}
	/// { "index": "my-other-index" }
	/// { "id": "my-other-search-template", "params": { "query_type": "match_all" }}
	/// 
	/// $ curl -H "Content-Type: application/x-ndjson" -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo
	/// </code>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/multi-search-template.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<MultiSearchTemplateResponse<TDocument>> MultiSearchTemplateAsync<TDocument>(Action<MultiSearchTemplateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new MultiSearchTemplateRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<MultiSearchTemplateRequestDescriptor<TDocument>, MultiSearchTemplateResponse<TDocument>, MultiSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime(OpenPointInTimeRequest request)
	{
		request.BeforeRequest();
		return DoRequest<OpenPointInTimeRequest, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync(OpenPointInTimeRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequest, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime<TDocument>(OpenPointInTimeRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime<TDocument>(Elastic.Clients.Elasticsearch.Indices indices)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Action<OpenPointInTimeRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime<TDocument>()
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime<TDocument>(Action<OpenPointInTimeRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime(OpenPointInTimeRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime(Elastic.Clients.Elasticsearch.Indices indices)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual OpenPointInTimeResponse OpenPointInTime(Elastic.Clients.Elasticsearch.Indices indices, Action<OpenPointInTimeRequestDescriptor> configureRequest)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<OpenPointInTimeRequestDescriptor, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync<TDocument>(OpenPointInTimeRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Action<OpenPointInTimeRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync<TDocument>(Action<OpenPointInTimeRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor<TDocument>, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync(OpenPointInTimeRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync(Elastic.Clients.Elasticsearch.Indices indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Open a point in time.
	/// </para>
	/// <para>
	/// A search request by default runs against the most recent visible data of the target indices,
	/// which is called point in time. Elasticsearch pit (point in time) is a lightweight view into the
	/// state of the data as it existed when initiated. In some cases, it’s preferred to perform multiple
	/// search requests using the same point in time. For example, if refreshes happen between
	/// <c>search_after</c> requests, then the results of those requests might not be consistent as changes happening
	/// between searches are only visible to the more recent point in time.
	/// </para>
	/// <para>
	/// A point in time must be opened explicitly before being used in search requests.
	/// </para>
	/// <para>
	/// A subsequent search request with the <c>pit</c> parameter must not specify <c>index</c>, <c>routing</c>, or <c>preference</c> values as these parameters are copied from the point in time.
	/// </para>
	/// <para>
	/// Just like regular searches, you can use <c>from</c> and <c>size</c> to page through point in time search results, up to the first 10,000 hits.
	/// If you want to retrieve more hits, use PIT with <c>search_after</c>.
	/// </para>
	/// <para>
	/// IMPORTANT: The open point in time request and each subsequent search request can return different identifiers; always use the most recently received ID for the next search request.
	/// </para>
	/// <para>
	/// When a PIT that contains shard failures is used in a search request, the missing are always reported in the search response as a <c>NoShardAvailableActionException</c> exception.
	/// To get rid of these exceptions, a new PIT needs to be created so that shards missing from the previous PIT can be handled, assuming they become available in the meantime.
	/// </para>
	/// <para>
	/// <strong>Keeping point in time alive</strong>
	/// </para>
	/// <para>
	/// The <c>keep_alive</c> parameter, which is passed to a open point in time request and search request, extends the time to live of the corresponding point in time.
	/// The value does not need to be long enough to process all data — it just needs to be long enough for the next request.
	/// </para>
	/// <para>
	/// Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments.
	/// Once the smaller segments are no longer needed they are deleted.
	/// However, open point-in-times prevent the old segments from being deleted since they are still in use.
	/// </para>
	/// <para>
	/// TIP: Keeping older segments alive means that more disk space and file handles are needed.
	/// Ensure that you have configured your nodes to have ample free file handles.
	/// </para>
	/// <para>
	/// Additionally, if a segment contains deleted or updated documents then the point in time must keep track of whether each document in the segment was live at the time of the initial search request.
	/// Ensure that your nodes have sufficient heap space if you have many open point-in-times on an index that is subject to ongoing deletes or updates.
	/// Note that a point-in-time doesn't prevent its associated indices from being deleted.
	/// You can check how many point-in-times (that is, search contexts) are open with the nodes stats API.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/point-in-time-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<OpenPointInTimeResponse> OpenPointInTimeAsync(Elastic.Clients.Elasticsearch.Indices indices, Action<OpenPointInTimeRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new OpenPointInTimeRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<OpenPointInTimeRequestDescriptor, OpenPointInTimeResponse, OpenPointInTimeRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PingResponse Ping(PingRequest request)
	{
		request.BeforeRequest();
		return DoRequest<PingRequest, PingResponse, PingRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PingResponse> PingAsync(PingRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<PingRequest, PingResponse, PingRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PingResponse Ping(PingRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<PingRequestDescriptor, PingResponse, PingRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PingResponse Ping()
	{
		var descriptor = new PingRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<PingRequestDescriptor, PingResponse, PingRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PingResponse Ping(Action<PingRequestDescriptor> configureRequest)
	{
		var descriptor = new PingRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<PingRequestDescriptor, PingResponse, PingRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PingResponse> PingAsync(PingRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<PingRequestDescriptor, PingResponse, PingRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PingResponse> PingAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new PingRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<PingRequestDescriptor, PingResponse, PingRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Ping the cluster.
	/// Get information about whether the cluster is running.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PingResponse> PingAsync(Action<PingRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new PingRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<PingRequestDescriptor, PingResponse, PingRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript(PutScriptRequest request)
	{
		request.BeforeRequest();
		return DoRequest<PutScriptRequest, PutScriptResponse, PutScriptRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync(PutScriptRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<PutScriptRequest, PutScriptResponse, PutScriptRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript<TDocument>(PutScriptRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript<TDocument>(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id, context);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript<TDocument>(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context, Action<PutScriptRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id, context);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript<TDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<PutScriptRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript(PutScriptRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context)
	{
		var descriptor = new PutScriptRequestDescriptor(id, context);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context, Action<PutScriptRequestDescriptor> configureRequest)
	{
		var descriptor = new PutScriptRequestDescriptor(id, context);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new PutScriptRequestDescriptor(id);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual PutScriptResponse PutScript(Elastic.Clients.Elasticsearch.Id id, Action<PutScriptRequestDescriptor> configureRequest)
	{
		var descriptor = new PutScriptRequestDescriptor(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync<TDocument>(PutScriptRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id, context);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context, Action<PutScriptRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id, context);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync<TDocument>(Elastic.Clients.Elasticsearch.Id id, Action<PutScriptRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor<TDocument>, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync(PutScriptRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor(id, context);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync(Elastic.Clients.Elasticsearch.Id id, Elastic.Clients.Elasticsearch.Name? context, Action<PutScriptRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor(id, context);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Create or update a script or search template.
	/// Creates or updates a stored script or search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/create-stored-script-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<PutScriptResponse> PutScriptAsync(Elastic.Clients.Elasticsearch.Id id, Action<PutScriptRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new PutScriptRequestDescriptor(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<PutScriptRequestDescriptor, PutScriptResponse, PutScriptRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval(RankEvalRequest request)
	{
		request.BeforeRequest();
		return DoRequest<RankEvalRequest, RankEvalResponse, RankEvalRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync(RankEvalRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<RankEvalRequest, RankEvalResponse, RankEvalRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval<TDocument>(RankEvalRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<RankEvalRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval<TDocument>()
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval<TDocument>(Action<RankEvalRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval(RankEvalRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new RankEvalRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval(Elastic.Clients.Elasticsearch.Indices? indices, Action<RankEvalRequestDescriptor> configureRequest)
	{
		var descriptor = new RankEvalRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval()
	{
		var descriptor = new RankEvalRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RankEvalResponse RankEval(Action<RankEvalRequestDescriptor> configureRequest)
	{
		var descriptor = new RankEvalRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync<TDocument>(RankEvalRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<RankEvalRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync<TDocument>(Action<RankEvalRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor<TDocument>, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync(RankEvalRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync(Elastic.Clients.Elasticsearch.Indices? indices, Action<RankEvalRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Evaluate ranked search results.
	/// </para>
	/// <para>
	/// Evaluate the quality of ranked search results over a set of typical search queries.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-rank-eval.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RankEvalResponse> RankEvalAsync(Action<RankEvalRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new RankEvalRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<RankEvalRequestDescriptor, RankEvalResponse, RankEvalRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexResponse Reindex(ReindexRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ReindexRequest, ReindexResponse, ReindexRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexResponse> ReindexAsync(ReindexRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ReindexRequest, ReindexResponse, ReindexRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexResponse Reindex<TDocument>(ReindexRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ReindexRequestDescriptor<TDocument>, ReindexResponse, ReindexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexResponse Reindex<TDocument>()
	{
		var descriptor = new ReindexRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<ReindexRequestDescriptor<TDocument>, ReindexResponse, ReindexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexResponse Reindex<TDocument>(Action<ReindexRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new ReindexRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ReindexRequestDescriptor<TDocument>, ReindexResponse, ReindexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexResponse Reindex(ReindexRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ReindexRequestDescriptor, ReindexResponse, ReindexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexResponse Reindex()
	{
		var descriptor = new ReindexRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<ReindexRequestDescriptor, ReindexResponse, ReindexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexResponse Reindex(Action<ReindexRequestDescriptor> configureRequest)
	{
		var descriptor = new ReindexRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ReindexRequestDescriptor, ReindexResponse, ReindexRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexResponse> ReindexAsync<TDocument>(ReindexRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRequestDescriptor<TDocument>, ReindexResponse, ReindexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexResponse> ReindexAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new ReindexRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRequestDescriptor<TDocument>, ReindexResponse, ReindexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexResponse> ReindexAsync<TDocument>(Action<ReindexRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ReindexRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRequestDescriptor<TDocument>, ReindexResponse, ReindexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexResponse> ReindexAsync(ReindexRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRequestDescriptor, ReindexResponse, ReindexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexResponse> ReindexAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new ReindexRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRequestDescriptor, ReindexResponse, ReindexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Reindex documents.
	/// </para>
	/// <para>
	/// Copy documents from a source to a destination.
	/// You can copy all documents to the destination index or reindex a subset of the documents.
	/// The source can be any existing index, alias, or data stream.
	/// The destination must differ from the source.
	/// For example, you cannot reindex a data stream into itself.
	/// </para>
	/// <para>
	/// IMPORTANT: Reindex requires <c>_source</c> to be enabled for all documents in the source.
	/// The destination should be configured as wanted before calling the reindex API.
	/// Reindex does not copy the settings from the source or its associated template.
	/// Mappings, shard counts, and replicas, for example, must be configured ahead of time.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following security privileges:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// The <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// The <c>write</c> index privilege for the destination data stream, index, or index alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// To automatically create a data stream or index with a reindex API request, you must have the <c>auto_configure</c>, <c>create_index</c>, or <c>manage</c> index privilege for the destination data stream, index, or alias.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If reindexing from a remote cluster, the <c>source.remote.user</c> must have the <c>monitor</c> cluster privilege and the <c>read</c> index privilege for the source data stream, index, or alias.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If reindexing from a remote cluster, you must explicitly allow the remote host in the <c>reindex.remote.whitelist</c> setting.
	/// Automatic data stream creation requires a matching index template with data stream enabled.
	/// </para>
	/// <para>
	/// The <c>dest</c> element can be configured like the index API to control optimistic concurrency control.
	/// Omitting <c>version_type</c> or setting it to <c>internal</c> causes Elasticsearch to blindly dump documents into the destination, overwriting any that happen to have the same ID.
	/// </para>
	/// <para>
	/// Setting <c>version_type</c> to <c>external</c> causes Elasticsearch to preserve the <c>version</c> from the source, create any documents that are missing, and update any documents that have an older version in the destination than they do in the source.
	/// </para>
	/// <para>
	/// Setting <c>op_type</c> to <c>create</c> causes the reindex API to create only missing documents in the destination.
	/// All existing documents will cause a version conflict.
	/// </para>
	/// <para>
	/// IMPORTANT: Because data streams are append-only, any reindex request to a destination data stream must have an <c>op_type</c> of <c>create</c>.
	/// A reindex can only add new documents to a destination data stream.
	/// It cannot update existing documents in a destination data stream.
	/// </para>
	/// <para>
	/// By default, version conflicts abort the reindex process.
	/// To continue reindexing if there are conflicts, set the <c>conflicts</c> request body property to <c>proceed</c>.
	/// In this case, the response includes a count of the version conflicts that were encountered.
	/// Note that the handling of other error types is unaffected by the <c>conflicts</c> property.
	/// Additionally, if you opt to count version conflicts, the operation could attempt to reindex more documents from the source than <c>max_docs</c> until it has successfully indexed <c>max_docs</c> documents into the target or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: The reindex API makes no effort to handle ID collisions.
	/// The last document written will "win" but the order isn't usually predictable so it is not a good idea to rely on this behavior.
	/// Instead, make sure that IDs are unique by using a script.
	/// </para>
	/// <para>
	/// <strong>Running reindex asynchronously</strong>
	/// </para>
	/// <para>
	/// If the request contains <c>wait_for_completion=false</c>, Elasticsearch performs some preflight checks, launches the request, and returns a task you can use to cancel or get the status of the task.
	/// Elasticsearch creates a record of this task as a document at <c>_tasks/&lt;task_id></c>.
	/// </para>
	/// <para>
	/// <strong>Reindex from multiple sources</strong>
	/// </para>
	/// <para>
	/// If you have many sources to reindex it is generally better to reindex them one at a time rather than using a glob pattern to pick up multiple sources.
	/// That way you can resume the process if there are any errors by removing the partially completed source and starting over.
	/// It also makes parallelizing the process fairly simple: split the list of sources to reindex and run each list in parallel.
	/// </para>
	/// <para>
	/// For example, you can use a bash script like this:
	/// </para>
	/// <code>
	/// for index in i1 i2 i3 i4 i5; do
	///   curl -HContent-Type:application/json -XPOST localhost:9200/_reindex?pretty -d'{
	///     "source": {
	///       "index": "'$index'"
	///     },
	///     "dest": {
	///       "index": "'$index'-reindexed"
	///     }
	///   }'
	/// done
	/// </code>
	/// <para>
	/// ** Throttling**
	/// </para>
	/// <para>
	/// Set <c>requests_per_second</c> to any positive decimal number (<c>1.4</c>, <c>6</c>, <c>1000</c>, for example) to throttle the rate at which reindex issues batches of index operations.
	/// Requests are throttled by padding each batch with a wait time.
	/// To turn off throttling, set <c>requests_per_second</c> to <c>-1</c>.
	/// </para>
	/// <para>
	/// The throttling is done by waiting between batches so that the scroll that reindex uses internally can be given a timeout that takes into account the padding.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is <c>1000</c>, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single bulk request, large batch sizes cause Elasticsearch to create many requests and then wait for a while before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Reindex supports sliced scroll to parallelize the reindexing process.
	/// This parallelization can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// You can slice a reindex request manually by providing a slice ID and total number of slices to each request.
	/// You can also let reindex automatically parallelize by using sliced scroll to slice on <c>_id</c>.
	/// The <c>slices</c> parameter specifies the number of slices to use.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to the reindex request just automates the manual process, creating sub-requests which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks API. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with <c>slices</c> will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of <c>slices</c>, each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with <c>slices</c> are distributed proportionally to each sub-request. Combine that with the previous point about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being reindexed.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source, though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If slicing automatically, setting <c>slices</c> to <c>auto</c> will choose a reasonable number for most indices.
	/// If slicing manually or otherwise tuning automatic slicing, use the following guidelines.
	/// </para>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index.
	/// If that number is large (for example, <c>500</c>), choose a lower number as too many slices will hurt performance.
	/// Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// <para>
	/// Indexing performance scales linearly across available resources with the number of slices.
	/// </para>
	/// <para>
	/// Whether query or indexing performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Modify documents during reindexing</strong>
	/// </para>
	/// <para>
	/// Like <c>_update_by_query</c>, reindex operations support a script that modifies the document.
	/// Unlike <c>_update_by_query</c>, the script is allowed to modify the document's metadata.
	/// </para>
	/// <para>
	/// Just as in <c>_update_by_query</c>, you can set <c>ctx.op</c> to change the operation that is run on the destination.
	/// For example, set <c>ctx.op</c> to <c>noop</c> if your script decides that the document doesn’t have to be indexed in the destination. This "no operation" will be reported in the <c>noop</c> counter in the response body.
	/// Set <c>ctx.op</c> to <c>delete</c> if your script decides that the document must be deleted from the destination.
	/// The deletion will be reported in the <c>deleted</c> counter in the response body.
	/// Setting <c>ctx.op</c> to anything else will return an error, as will setting any other field in <c>ctx</c>.
	/// </para>
	/// <para>
	/// Think of the possibilities! Just be careful; you are able to change:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>_id</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_index</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_version</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>_routing</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Setting <c>_version</c> to <c>null</c> or clearing it from the <c>ctx</c> map is just like not sending the version in an indexing request.
	/// It will cause the document to be overwritten in the destination regardless of the version on the target or the version type you use in the reindex API.
	/// </para>
	/// <para>
	/// <strong>Reindex from remote</strong>
	/// </para>
	/// <para>
	/// Reindex supports reindexing from a remote Elasticsearch cluster.
	/// The <c>host</c> parameter must contain a scheme, host, port, and optional path.
	/// The <c>username</c> and <c>password</c> parameters are optional and when they are present the reindex operation will connect to the remote Elasticsearch node using basic authentication.
	/// Be sure to use HTTPS when using basic authentication or the password will be sent in plain text.
	/// There are a range of settings available to configure the behavior of the HTTPS connection.
	/// </para>
	/// <para>
	/// When using Elastic Cloud, it is also possible to authenticate against the remote cluster through the use of a valid API key.
	/// Remote hosts must be explicitly allowed with the <c>reindex.remote.whitelist</c> setting.
	/// It can be set to a comma delimited list of allowed remote host and port combinations.
	/// Scheme is ignored; only the host and port are used.
	/// For example:
	/// </para>
	/// <code>
	/// reindex.remote.whitelist: [otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"]
	/// </code>
	/// <para>
	/// The list of allowed hosts must be configured on any nodes that will coordinate the reindex.
	/// This feature should work with remote clusters of any version of Elasticsearch.
	/// This should enable you to upgrade from any version of Elasticsearch to the current version by reindexing from a cluster of the old version.
	/// </para>
	/// <para>
	/// WARNING: Elasticsearch does not support forward compatibility across major versions.
	/// For example, you cannot reindex from a 7.x cluster into a 6.x cluster.
	/// </para>
	/// <para>
	/// To enable queries sent to older versions of Elasticsearch, the <c>query</c> parameter is sent directly to the remote host without validation or modification.
	/// </para>
	/// <para>
	/// NOTE: Reindexing from remote clusters does not support manual or automatic slicing.
	/// </para>
	/// <para>
	/// Reindexing from a remote server uses an on-heap buffer that defaults to a maximum size of 100mb.
	/// If the remote index includes very large documents you'll need to use a smaller batch size.
	/// It is also possible to set the socket read timeout on the remote connection with the <c>socket_timeout</c> field and the connection timeout with the <c>connect_timeout</c> field.
	/// Both default to 30 seconds.
	/// </para>
	/// <para>
	/// <strong>Configuring SSL parameters</strong>
	/// </para>
	/// <para>
	/// Reindex from remote supports configurable SSL settings.
	/// These must be specified in the <c>elasticsearch.yml</c> file, with the exception of the secure settings, which you add in the Elasticsearch keystore.
	/// It is not possible to configure SSL in the body of the reindex request.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexResponse> ReindexAsync(Action<ReindexRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ReindexRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRequestDescriptor, ReindexResponse, ReindexRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexRethrottleResponse ReindexRethrottle(ReindexRethrottleRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ReindexRethrottleRequest, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexRethrottleResponse> ReindexRethrottleAsync(ReindexRethrottleRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ReindexRethrottleRequest, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexRethrottleResponse ReindexRethrottle(ReindexRethrottleRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ReindexRethrottleRequestDescriptor, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexRethrottleResponse ReindexRethrottle(Elastic.Clients.Elasticsearch.Id taskId)
	{
		var descriptor = new ReindexRethrottleRequestDescriptor(taskId);
		descriptor.BeforeRequest();
		return DoRequest<ReindexRethrottleRequestDescriptor, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ReindexRethrottleResponse ReindexRethrottle(Elastic.Clients.Elasticsearch.Id taskId, Action<ReindexRethrottleRequestDescriptor> configureRequest)
	{
		var descriptor = new ReindexRethrottleRequestDescriptor(taskId);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ReindexRethrottleRequestDescriptor, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexRethrottleResponse> ReindexRethrottleAsync(ReindexRethrottleRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRethrottleRequestDescriptor, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexRethrottleResponse> ReindexRethrottleAsync(Elastic.Clients.Elasticsearch.Id taskId, CancellationToken cancellationToken = default)
	{
		var descriptor = new ReindexRethrottleRequestDescriptor(taskId);
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRethrottleRequestDescriptor, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle a reindex operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular reindex operation.
	/// For example:
	/// </para>
	/// <code>
	/// POST _reindex/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1
	/// </code>
	/// <para>
	/// Rethrottling that speeds up the query takes effect immediately.
	/// Rethrottling that slows down the query will take effect after completing the current batch.
	/// This behavior prevents scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-reindex.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ReindexRethrottleResponse> ReindexRethrottleAsync(Elastic.Clients.Elasticsearch.Id taskId, Action<ReindexRethrottleRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ReindexRethrottleRequestDescriptor(taskId);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ReindexRethrottleRequestDescriptor, ReindexRethrottleResponse, ReindexRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RenderSearchTemplateResponse RenderSearchTemplate(RenderSearchTemplateRequest request)
	{
		request.BeforeRequest();
		return DoRequest<RenderSearchTemplateRequest, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RenderSearchTemplateResponse> RenderSearchTemplateAsync(RenderSearchTemplateRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<RenderSearchTemplateRequest, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RenderSearchTemplateResponse RenderSearchTemplate<TDocument>(RenderSearchTemplateRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<RenderSearchTemplateRequestDescriptor<TDocument>, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RenderSearchTemplateResponse RenderSearchTemplate<TDocument>()
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<RenderSearchTemplateRequestDescriptor<TDocument>, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RenderSearchTemplateResponse RenderSearchTemplate<TDocument>(Action<RenderSearchTemplateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<RenderSearchTemplateRequestDescriptor<TDocument>, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RenderSearchTemplateResponse RenderSearchTemplate(RenderSearchTemplateRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<RenderSearchTemplateRequestDescriptor, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RenderSearchTemplateResponse RenderSearchTemplate()
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<RenderSearchTemplateRequestDescriptor, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual RenderSearchTemplateResponse RenderSearchTemplate(Action<RenderSearchTemplateRequestDescriptor> configureRequest)
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<RenderSearchTemplateRequestDescriptor, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RenderSearchTemplateResponse> RenderSearchTemplateAsync<TDocument>(RenderSearchTemplateRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<RenderSearchTemplateRequestDescriptor<TDocument>, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RenderSearchTemplateResponse> RenderSearchTemplateAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<RenderSearchTemplateRequestDescriptor<TDocument>, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RenderSearchTemplateResponse> RenderSearchTemplateAsync<TDocument>(Action<RenderSearchTemplateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<RenderSearchTemplateRequestDescriptor<TDocument>, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RenderSearchTemplateResponse> RenderSearchTemplateAsync(RenderSearchTemplateRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<RenderSearchTemplateRequestDescriptor, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RenderSearchTemplateResponse> RenderSearchTemplateAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<RenderSearchTemplateRequestDescriptor, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Render a search template.
	/// </para>
	/// <para>
	/// Render a search template as a search request body.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/render-search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<RenderSearchTemplateResponse> RenderSearchTemplateAsync(Action<RenderSearchTemplateRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new RenderSearchTemplateRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<RenderSearchTemplateRequestDescriptor, RenderSearchTemplateResponse, RenderSearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ScriptsPainlessExecuteResponse<TResult> ScriptsPainlessExecute<TResult>(ScriptsPainlessExecuteRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ScriptsPainlessExecuteRequest, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ScriptsPainlessExecuteResponse<TResult>> ScriptsPainlessExecuteAsync<TResult>(ScriptsPainlessExecuteRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ScriptsPainlessExecuteRequest, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ScriptsPainlessExecuteResponse<TResult> ScriptsPainlessExecute<TResult>(ScriptsPainlessExecuteRequestDescriptor<TResult> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<ScriptsPainlessExecuteRequestDescriptor<TResult>, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ScriptsPainlessExecuteResponse<TResult> ScriptsPainlessExecute<TResult>()
	{
		var descriptor = new ScriptsPainlessExecuteRequestDescriptor<TResult>();
		descriptor.BeforeRequest();
		return DoRequest<ScriptsPainlessExecuteRequestDescriptor<TResult>, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ScriptsPainlessExecuteResponse<TResult> ScriptsPainlessExecute<TResult>(Action<ScriptsPainlessExecuteRequestDescriptor<TResult>> configureRequest)
	{
		var descriptor = new ScriptsPainlessExecuteRequestDescriptor<TResult>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<ScriptsPainlessExecuteRequestDescriptor<TResult>, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ScriptsPainlessExecuteResponse<TResult>> ScriptsPainlessExecuteAsync<TResult>(ScriptsPainlessExecuteRequestDescriptor<TResult> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<ScriptsPainlessExecuteRequestDescriptor<TResult>, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ScriptsPainlessExecuteResponse<TResult>> ScriptsPainlessExecuteAsync<TResult>(CancellationToken cancellationToken = default)
	{
		var descriptor = new ScriptsPainlessExecuteRequestDescriptor<TResult>();
		descriptor.BeforeRequest();
		return DoRequestAsync<ScriptsPainlessExecuteRequestDescriptor<TResult>, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a script.
	/// Runs a script and returns a result.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-execute-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ScriptsPainlessExecuteResponse<TResult>> ScriptsPainlessExecuteAsync<TResult>(Action<ScriptsPainlessExecuteRequestDescriptor<TResult>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new ScriptsPainlessExecuteRequestDescriptor<TResult>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<ScriptsPainlessExecuteRequestDescriptor<TResult>, ScriptsPainlessExecuteResponse<TResult>, ScriptsPainlessExecuteRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a scrolling search.
	/// </para>
	/// <para>
	/// IMPORTANT: The scroll API is no longer recommend for deep pagination. If you need to preserve the index state while paging through more than 10,000 hits, use the <c>search_after</c> parameter with a point in time (PIT).
	/// </para>
	/// <para>
	/// The scroll API gets large sets of results from a single scrolling search request.
	/// To get the necessary scroll ID, submit a search API request that includes an argument for the <c>scroll</c> query parameter.
	/// The <c>scroll</c> parameter indicates how long Elasticsearch should retain the search context for the request.
	/// The search response returns a scroll ID in the <c>_scroll_id</c> response body parameter.
	/// You can then use the scroll ID with the scroll API to retrieve the next batch of results for the request.
	/// If the Elasticsearch security features are enabled, the access to the results of a specific scroll ID is restricted to the user or API key that submitted the search.
	/// </para>
	/// <para>
	/// You can also use the scroll API to specify a new scroll parameter that extends or shortens the retention period for the search context.
	/// </para>
	/// <para>
	/// IMPORTANT: Results from a scrolling search reflect the state of the index at the time of the initial search request. Subsequent indexing or document changes only affect later search and scroll requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual ScrollResponse<TDocument> Scroll<TDocument>(ScrollRequest request)
	{
		request.BeforeRequest();
		return DoRequest<ScrollRequest, ScrollResponse<TDocument>, ScrollRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Run a scrolling search.
	/// </para>
	/// <para>
	/// IMPORTANT: The scroll API is no longer recommend for deep pagination. If you need to preserve the index state while paging through more than 10,000 hits, use the <c>search_after</c> parameter with a point in time (PIT).
	/// </para>
	/// <para>
	/// The scroll API gets large sets of results from a single scrolling search request.
	/// To get the necessary scroll ID, submit a search API request that includes an argument for the <c>scroll</c> query parameter.
	/// The <c>scroll</c> parameter indicates how long Elasticsearch should retain the search context for the request.
	/// The search response returns a scroll ID in the <c>_scroll_id</c> response body parameter.
	/// You can then use the scroll ID with the scroll API to retrieve the next batch of results for the request.
	/// If the Elasticsearch security features are enabled, the access to the results of a specific scroll ID is restricted to the user or API key that submitted the search.
	/// </para>
	/// <para>
	/// You can also use the scroll API to specify a new scroll parameter that extends or shortens the retention period for the search context.
	/// </para>
	/// <para>
	/// IMPORTANT: Results from a scrolling search reflect the state of the index at the time of the initial search request. Subsequent indexing or document changes only affect later search and scroll requests.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/scroll-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<ScrollResponse<TDocument>> ScrollAsync<TDocument>(ScrollRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<ScrollRequest, ScrollResponse<TDocument>, ScrollRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchResponse<TDocument> Search<TDocument>(SearchRequest request)
	{
		request.BeforeRequest();
		return DoRequest<SearchRequest, SearchResponse<TDocument>, SearchRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchResponse<TDocument>> SearchAsync<TDocument>(SearchRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<SearchRequest, SearchResponse<TDocument>, SearchRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchResponse<TDocument> Search<TDocument>(SearchRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchResponse<TDocument> Search<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new SearchRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchResponse<TDocument> Search<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchResponse<TDocument> Search<TDocument>()
	{
		var descriptor = new SearchRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchResponse<TDocument> Search<TDocument>(Action<SearchRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchResponse<TDocument>> SearchAsync<TDocument>(SearchRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchResponse<TDocument>> SearchAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchResponse<TDocument>> SearchAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchResponse<TDocument>> SearchAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search.
	/// </para>
	/// <para>
	/// Get search hits that match the query defined in the request.
	/// You can provide search queries using the <c>q</c> query string parameter or the request body.
	/// If both are specified, only the query parameter is used.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the read index privilege for the target data stream, index, or alias. For cross-cluster search, refer to the documentation about configuring CCS privileges.
	/// To search a point in time (PIT) for an alias, you must have the <c>read</c> index privilege for the alias's data streams or indices.
	/// </para>
	/// <para>
	/// <strong>Search slicing</strong>
	/// </para>
	/// <para>
	/// When paging through a large number of documents, it can be helpful to split the search into multiple slices to consume them independently with the <c>slice</c> and <c>pit</c> properties.
	/// By default the splitting is done first on the shards, then locally on each shard.
	/// The local splitting partitions the shard into contiguous ranges based on Lucene document IDs.
	/// </para>
	/// <para>
	/// For instance if the number of shards is equal to 2 and you request 4 slices, the slices 0 and 2 are assigned to the first shard and the slices 1 and 3 are assigned to the second shard.
	/// </para>
	/// <para>
	/// IMPORTANT: The same point-in-time ID should be used for all slices.
	/// If different PIT IDs are used, slices can overlap and miss documents.
	/// This situation can occur because the splitting criterion is based on Lucene document IDs, which are not stable across changes to the index.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-search.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchResponse<TDocument>> SearchAsync<TDocument>(Action<SearchRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchRequestDescriptor<TDocument>, SearchResponse<TDocument>, SearchRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt(SearchMvtRequest request)
	{
		request.BeforeRequest();
		return DoRequest<SearchMvtRequest, SearchMvtResponse, SearchMvtRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync(SearchMvtRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<SearchMvtRequest, SearchMvtResponse, SearchMvtRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt<TDocument>(SearchMvtRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(indices, field, zoom, x, y);
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, Action<SearchMvtRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(indices, field, zoom, x, y);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt<TDocument>(Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(field, zoom, x, y);
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt<TDocument>(Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, Action<SearchMvtRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(field, zoom, x, y);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt(SearchMvtRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y)
	{
		var descriptor = new SearchMvtRequestDescriptor(indices, field, zoom, x, y);
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchMvtResponse SearchMvt(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, Action<SearchMvtRequestDescriptor> configureRequest)
	{
		var descriptor = new SearchMvtRequestDescriptor(indices, field, zoom, x, y);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchMvtRequestDescriptor, SearchMvtResponse, SearchMvtRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync<TDocument>(SearchMvtRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(indices, field, zoom, x, y);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, Action<SearchMvtRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(indices, field, zoom, x, y);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync<TDocument>(Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(field, zoom, x, y);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync<TDocument>(Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, Action<SearchMvtRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchMvtRequestDescriptor<TDocument>(field, zoom, x, y);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor<TDocument>, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync(SearchMvtRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchMvtRequestDescriptor(indices, field, zoom, x, y);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Search a vector tile.
	/// </para>
	/// <para>
	/// Search a vector tile for geospatial values.
	/// Before using this API, you should be familiar with the Mapbox vector tile specification.
	/// The API returns results as a binary mapbox vector tile.
	/// </para>
	/// <para>
	/// Internally, Elasticsearch translates a vector tile search API request into a search containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>geo_bounding_box</c> query on the <c>&lt;field></c>. The query uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A <c>geotile_grid</c> or <c>geohex_grid</c> aggregation on the <c>&lt;field></c>. The <c>grid_agg</c> parameter determines the aggregation type. The aggregation uses the <c>&lt;zoom>/&lt;x>/&lt;y></c> tile as a bounding box.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Optionally, a <c>geo_bounds</c> aggregation on the <c>&lt;field></c>. The search only includes this aggregation if the <c>exact_bounds</c> parameter is <c>true</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// If the optional parameter <c>with_labels</c> is <c>true</c>, the internal search will include a dynamic runtime field that calls the <c>getLabelPosition</c> function of the geometry doc value. This enables the generation of new point features containing suggested geometry labels, so that, for example, multi-polygons will have only one label.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// For example, Elasticsearch may translate a vector tile search API request with a <c>grid_agg</c> argument of <c>geotile</c> and an <c>exact_bounds</c> argument of <c>true</c> into the following search
	/// </para>
	/// <code>
	/// GET my-index/_search
	/// {
	///   "size": 10000,
	///   "query": {
	///     "geo_bounding_box": {
	///       "my-geo-field": {
	///         "top_left": {
	///           "lat": -40.979898069620134,
	///           "lon": -45
	///         },
	///         "bottom_right": {
	///           "lat": -66.51326044311186,
	///           "lon": 0
	///         }
	///       }
	///     }
	///   },
	///   "aggregations": {
	///     "grid": {
	///       "geotile_grid": {
	///         "field": "my-geo-field",
	///         "precision": 11,
	///         "size": 65536,
	///         "bounds": {
	///           "top_left": {
	///             "lat": -40.979898069620134,
	///             "lon": -45
	///           },
	///           "bottom_right": {
	///             "lat": -66.51326044311186,
	///             "lon": 0
	///           }
	///         }
	///       }
	///     },
	///     "bounds": {
	///       "geo_bounds": {
	///         "field": "my-geo-field",
	///         "wrap_longitude": false
	///       }
	///     }
	///   }
	/// }
	/// </code>
	/// <para>
	/// The API returns results as a binary Mapbox vector tile.
	/// Mapbox vector tiles are encoded as Google Protobufs (PBF). By default, the tile contains three layers:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A <c>hits</c> layer containing a feature for each <c>&lt;field></c> value matching the <c>geo_bounding_box</c> query.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// An <c>aggs</c> layer containing a feature for each cell of the <c>geotile_grid</c> or <c>geohex_grid</c>. The layer only contains features for cells with matching data.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// A meta layer containing:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// A feature containing a bounding box. By default, this is the bounding box of the tile.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Value ranges for any sub-aggregations on the <c>geotile_grid</c> or <c>geohex_grid</c>.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Metadata for the search.
	/// </para>
	/// </item>
	/// </list>
	/// </item>
	/// </list>
	/// <para>
	/// The API only returns features that can display at its zoom level.
	/// For example, if a polygon feature has no area at its zoom level, the API omits it.
	/// The API returns errors as UTF-8 encoded JSON.
	/// </para>
	/// <para>
	/// IMPORTANT: You can specify several options for this API as either a query parameter or request body parameter.
	/// If you specify both parameters, the query parameter takes precedence.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geotile</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geotile</c>, you can use cells in the <c>aggs</c> layer as tiles for lower zoom levels.
	/// <c>grid_precision</c> represents the additional zoom levels available through these cells. The final precision is computed by as follows: <c>&lt;zoom> + grid_precision</c>.
	/// For example, if <c>&lt;zoom></c> is 7 and <c>grid_precision</c> is 8, then the <c>geotile_grid</c> aggregation will use a precision of 15.
	/// The maximum final precision is 29.
	/// The <c>grid_precision</c> also determines the number of cells for the grid as follows: <c>(2^grid_precision) x (2^grid_precision)</c>.
	/// For example, a value of 8 divides the tile into a grid of 256 x 256 cells.
	/// The <c>aggs</c> layer only contains features for cells with matching data.
	/// </para>
	/// <para>
	/// <strong>Grid precision for geohex</strong>
	/// </para>
	/// <para>
	/// For a <c>grid_agg</c> of <c>geohex</c>, Elasticsearch uses <c>&lt;zoom></c> and <c>grid_precision</c> to calculate a final precision as follows: <c>&lt;zoom> + grid_precision</c>.
	/// </para>
	/// <para>
	/// This precision determines the H3 resolution of the hexagonal cells produced by the <c>geohex</c> aggregation.
	/// The following table maps the H3 resolution for each precision.
	/// For example, if <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 3, the precision is 6.
	/// At a precision of 6, hexagonal cells have an H3 resolution of 2.
	/// If <c>&lt;zoom></c> is 3 and <c>grid_precision</c> is 4, the precision is 7.
	/// At a precision of 7, hexagonal cells have an H3 resolution of 3.
	/// </para>
	/// <para>
	/// | Precision | Unique tile bins | H3 resolution | Unique hex bins |	Ratio |
	/// | --------- | ---------------- | ------------- | ----------------| ----- |
	/// | 1  | 4                  | 0  | 122             | 30.5           |
	/// | 2  | 16                 | 0  | 122             | 7.625          |
	/// | 3  | 64                 | 1  | 842             | 13.15625       |
	/// | 4  | 256                | 1  | 842             | 3.2890625      |
	/// | 5  | 1024               | 2  | 5882            | 5.744140625    |
	/// | 6  | 4096               | 2  | 5882            | 1.436035156    |
	/// | 7  | 16384              | 3  | 41162           | 2.512329102    |
	/// | 8  | 65536              | 3  | 41162           | 0.6280822754   |
	/// | 9  | 262144             | 4  | 288122          | 1.099098206    |
	/// | 10 | 1048576            | 4  | 288122          | 0.2747745514   |
	/// | 11 | 4194304            | 5  | 2016842         | 0.4808526039   |
	/// | 12 | 16777216           | 6  | 14117882        | 0.8414913416   |
	/// | 13 | 67108864           | 6  | 14117882        | 0.2103728354   |
	/// | 14 | 268435456          | 7  | 98825162        | 0.3681524172   |
	/// | 15 | 1073741824         | 8  | 691776122       | 0.644266719    |
	/// | 16 | 4294967296         | 8  | 691776122       | 0.1610666797   |
	/// | 17 | 17179869184        | 9  | 4842432842      | 0.2818666889   |
	/// | 18 | 68719476736        | 10 | 33897029882     | 0.4932667053   |
	/// | 19 | 274877906944       | 11 | 237279209162    | 0.8632167343   |
	/// | 20 | 1099511627776      | 11 | 237279209162    | 0.2158041836   |
	/// | 21 | 4398046511104      | 12 | 1660954464122   | 0.3776573213   |
	/// | 22 | 17592186044416     | 13 | 11626681248842  | 0.6609003122   |
	/// | 23 | 70368744177664     | 13 | 11626681248842  | 0.165225078    |
	/// | 24 | 281474976710656    | 14 | 81386768741882  | 0.2891438866   |
	/// | 25 | 1125899906842620   | 15 | 569707381193162 | 0.5060018015   |
	/// | 26 | 4503599627370500   | 15 | 569707381193162 | 0.1265004504   |
	/// | 27 | 18014398509482000  | 15 | 569707381193162 | 0.03162511259  |
	/// | 28 | 72057594037927900  | 15 | 569707381193162 | 0.007906278149 |
	/// | 29 | 288230376151712000 | 15 | 569707381193162 | 0.001976569537 |
	/// </para>
	/// <para>
	/// Hexagonal cells don't align perfectly on a vector tile.
	/// Some cells may intersect more than one vector tile.
	/// To compute the H3 resolution for each precision, Elasticsearch compares the average density of hexagonal bins at each resolution with the average density of tile bins at each zoom level.
	/// Elasticsearch uses the H3 resolution that is closest to the corresponding geotile density.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-vector-tile-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchMvtResponse> SearchMvtAsync(Elastic.Clients.Elasticsearch.Indices indices, Elastic.Clients.Elasticsearch.Field field, int zoom, int x, int y, Action<SearchMvtRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchMvtRequestDescriptor(indices, field, zoom, x, y);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchMvtRequestDescriptor, SearchMvtResponse, SearchMvtRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards(SearchShardsRequest request)
	{
		request.BeforeRequest();
		return DoRequest<SearchShardsRequest, SearchShardsResponse, SearchShardsRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync(SearchShardsRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<SearchShardsRequest, SearchShardsResponse, SearchShardsRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards<TDocument>(SearchShardsRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchShardsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards<TDocument>()
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards<TDocument>(Action<SearchShardsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards(SearchShardsRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new SearchShardsRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchShardsRequestDescriptor> configureRequest)
	{
		var descriptor = new SearchShardsRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards()
	{
		var descriptor = new SearchShardsRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchShardsResponse SearchShards(Action<SearchShardsRequestDescriptor> configureRequest)
	{
		var descriptor = new SearchShardsRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync<TDocument>(SearchShardsRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchShardsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync<TDocument>(Action<SearchShardsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor<TDocument>, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync(SearchShardsRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchShardsRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync(CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor();
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get the search shards.
	/// </para>
	/// <para>
	/// Get the indices and shards that a search request would be run against.
	/// This information can be useful for working out issues or planning optimizations with routing and shard preferences.
	/// When filtered aliases are used, the filter is returned as part of the <c>indices</c> section.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>view_index_metadata</c> or <c>manage</c> index privilege for the target data stream, index, or alias.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-shards.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchShardsResponse> SearchShardsAsync(Action<SearchShardsRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchShardsRequestDescriptor();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchShardsRequestDescriptor, SearchShardsResponse, SearchShardsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchTemplateResponse<TDocument> SearchTemplate<TDocument>(SearchTemplateRequest request)
	{
		request.BeforeRequest();
		return DoRequest<SearchTemplateRequest, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchTemplateResponse<TDocument>> SearchTemplateAsync<TDocument>(SearchTemplateRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<SearchTemplateRequest, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchTemplateResponse<TDocument> SearchTemplate<TDocument>(SearchTemplateRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchTemplateResponse<TDocument> SearchTemplate<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices)
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchTemplateResponse<TDocument> SearchTemplate<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchTemplateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchTemplateResponse<TDocument> SearchTemplate<TDocument>()
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual SearchTemplateResponse<TDocument> SearchTemplate<TDocument>(Action<SearchTemplateRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchTemplateResponse<TDocument>> SearchTemplateAsync<TDocument>(SearchTemplateRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchTemplateResponse<TDocument>> SearchTemplateAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchTemplateResponse<TDocument>> SearchTemplateAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices? indices, Action<SearchTemplateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchTemplateResponse<TDocument>> SearchTemplateAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Run a search with a search template.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-template-api.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<SearchTemplateResponse<TDocument>> SearchTemplateAsync<TDocument>(Action<SearchTemplateRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new SearchTemplateRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<SearchTemplateRequestDescriptor<TDocument>, SearchTemplateResponse<TDocument>, SearchTemplateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum(TermsEnumRequest request)
	{
		request.BeforeRequest();
		return DoRequest<TermsEnumRequest, TermsEnumResponse, TermsEnumRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync(TermsEnumRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<TermsEnumRequest, TermsEnumResponse, TermsEnumRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum<TDocument>(TermsEnumRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum<TDocument>(Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Action<TermsEnumRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum<TDocument>()
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum<TDocument>(Action<TermsEnumRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum(TermsEnumRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum(Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new TermsEnumRequestDescriptor(index);
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermsEnumResponse TermsEnum(Elastic.Clients.Elasticsearch.IndexName index, Action<TermsEnumRequestDescriptor> configureRequest)
	{
		var descriptor = new TermsEnumRequestDescriptor(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermsEnumRequestDescriptor, TermsEnumResponse, TermsEnumRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync<TDocument>(TermsEnumRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Action<TermsEnumRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync<TDocument>(Action<TermsEnumRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermsEnumRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor<TDocument>, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync(TermsEnumRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync(Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermsEnumRequestDescriptor(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get terms in an index.
	/// </para>
	/// <para>
	/// Discover terms that match a partial string in an index.
	/// This API is designed for low-latency look-ups used in auto-complete scenarios.
	/// </para>
	/// <para>
	/// info
	/// The terms enum API may return terms from deleted documents. Deleted documents are initially only marked as deleted. It is not until their segments are merged that documents are actually deleted. Until that happens, the terms enum API will return terms from these documents.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/search-terms-enum.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermsEnumResponse> TermsEnumAsync(Elastic.Clients.Elasticsearch.IndexName index, Action<TermsEnumRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermsEnumRequestDescriptor(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermsEnumRequestDescriptor, TermsEnumResponse, TermsEnumRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TermVectorsRequest<TDocument> request)
	{
		request.BeforeRequest();
		return DoRequest<TermVectorsRequest<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TermVectorsRequest<TDocument> request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<TermVectorsRequest<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TermVectorsRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TDocument document)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TDocument document, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(Elastic.Clients.Elasticsearch.Id? id)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual TermVectorsResponse Termvectors<TDocument>(Elastic.Clients.Elasticsearch.Id? id, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TermVectorsRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id? id, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.IndexName index, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TDocument document, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id? id, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.Id? id, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Get term vector information.
	/// </para>
	/// <para>
	/// Get information and statistics about terms in the fields of a particular document.
	/// </para>
	/// <para>
	/// You can retrieve term vectors for documents stored in the index or for artificial documents passed in the body of the request.
	/// You can specify the fields you are interested in through the <c>fields</c> parameter or by adding the fields to the request body.
	/// For example:
	/// </para>
	/// <code>
	/// GET /my-index-000001/_termvectors/1?fields=message
	/// </code>
	/// <para>
	/// Fields can be specified using wildcards, similar to the multi match query.
	/// </para>
	/// <para>
	/// Term vectors are real-time by default, not near real-time.
	/// This can be changed by setting <c>realtime</c> parameter to <c>false</c>.
	/// </para>
	/// <para>
	/// You can request three types of values: <em>term information</em>, <em>term statistics</em>, and <em>field statistics</em>.
	/// By default, all term information and field statistics are returned for all fields but term statistics are excluded.
	/// </para>
	/// <para>
	/// <strong>Term information</strong>
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// term frequency in the field (always returned)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term positions (<c>positions: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// start and end offsets (<c>offsets: true</c>)
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// term payloads (<c>payloads: true</c>), as base64 encoded bytes
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If the requested information wasn't stored in the index, it will be computed on the fly if possible.
	/// Additionally, term vectors could be computed for documents not even existing in the index, but instead provided by the user.
	/// </para>
	/// <para>
	/// warn
	/// Start and end offsets assume UTF-16 encoding is being used. If you want to use these offsets in order to get the original text that produced this token, you should make sure that the string you are taking a sub-string of is also encoded using UTF-16.
	/// </para>
	/// <para>
	/// <strong>Behaviour</strong>
	/// </para>
	/// <para>
	/// The term and field statistics are not accurate.
	/// Deleted documents are not taken into account.
	/// The information is only retrieved for the shard the requested document resides in.
	/// The term and field statistics are therefore only useful as relative measures whereas the absolute numbers have no meaning in this context.
	/// By default, when requesting term vectors of artificial documents, a shard to get the statistics from is randomly selected.
	/// Use <c>routing</c> only to hit a particular shard.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-termvectors.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<TermVectorsResponse> TermvectorsAsync<TDocument>(Elastic.Clients.Elasticsearch.Id? id, Action<TermVectorsRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new TermVectorsRequestDescriptor<TDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<TermVectorsRequestDescriptor<TDocument>, TermVectorsResponse, TermVectorsRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(UpdateRequest<TDocument, TPartialDocument> request)
	{
		request.BeforeRequest();
		return DoRequest<UpdateRequest<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(UpdateRequest<TDocument, TPartialDocument> request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<UpdateRequest<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(UpdateRequestDescriptor<TDocument, TPartialDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(TDocument document)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(TDocument document, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.Id id)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(id);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateResponse<TDocument> Update<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.Id id, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(UpdateRequestDescriptor<TDocument, TPartialDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(index, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.IndexName index, Elastic.Clients.Elasticsearch.Id id, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(index, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(TDocument document, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(TDocument document, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, index);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.IndexName index, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, index);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, id);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(TDocument document, Elastic.Clients.Elasticsearch.Id id, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(document, id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.Id id, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(id);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update a document.
	/// </para>
	/// <para>
	/// Update a document by running a script or passing a partial document.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the <c>index</c> or <c>write</c> index privilege for the target index or index alias.
	/// </para>
	/// <para>
	/// The script can update, delete, or skip modifying the document.
	/// The API also supports passing a partial document, which is merged into the existing document.
	/// To fully replace an existing document, use the index API.
	/// This operation:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Gets the document (collocated with the shard) from the index.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Runs the specified script.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Indexes the result.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// The document must still be reindexed, but using this API removes some network roundtrips and reduces chances of version conflicts between the GET and the index operation.
	/// </para>
	/// <para>
	/// The <c>_source</c> field must be enabled to use this API.
	/// In addition to <c>_source</c>, you can access the following variables through the <c>ctx</c> map: <c>_index</c>, <c>_type</c>, <c>_id</c>, <c>_version</c>, <c>_routing</c>, and <c>_now</c> (the current timestamp).
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateResponse<TDocument>> UpdateAsync<TDocument, TPartialDocument>(Elastic.Clients.Elasticsearch.Id id, Action<UpdateRequestDescriptor<TDocument, TPartialDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateRequestDescriptor<TDocument, TPartialDocument>(id);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateRequestDescriptor<TDocument, TPartialDocument>, UpdateResponse<TDocument>, UpdateRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery(UpdateByQueryRequest request)
	{
		request.BeforeRequest();
		return DoRequest<UpdateByQueryRequest, UpdateByQueryResponse, UpdateByQueryRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync(UpdateByQueryRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequest, UpdateByQueryResponse, UpdateByQueryRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery<TDocument>(UpdateByQueryRequestDescriptor<TDocument> descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery<TDocument>(Elastic.Clients.Elasticsearch.Indices indices)
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Action<UpdateByQueryRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery<TDocument>()
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery<TDocument>(Action<UpdateByQueryRequestDescriptor<TDocument>> configureRequest)
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery(UpdateByQueryRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery(Elastic.Clients.Elasticsearch.Indices indices)
	{
		var descriptor = new UpdateByQueryRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryResponse UpdateByQuery(Elastic.Clients.Elasticsearch.Indices indices, Action<UpdateByQueryRequestDescriptor> configureRequest)
	{
		var descriptor = new UpdateByQueryRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRequestDescriptor, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync<TDocument>(UpdateByQueryRequestDescriptor<TDocument> descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync<TDocument>(Elastic.Clients.Elasticsearch.Indices indices, Action<UpdateByQueryRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync<TDocument>(CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>();
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync<TDocument>(Action<UpdateByQueryRequestDescriptor<TDocument>> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRequestDescriptor<TDocument>();
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor<TDocument>, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync(UpdateByQueryRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync(Elastic.Clients.Elasticsearch.Indices indices, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRequestDescriptor(indices);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Update documents.
	/// Updates documents that match the specified query.
	/// If no query is specified, performs an update on every document in the data stream or index without modifying the source, which is useful for picking up mapping changes.
	/// </para>
	/// <para>
	/// If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or alias:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>read</c>
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>index</c> or <c>write</c>
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// You can specify the query criteria in the request URI or the request body using the same syntax as the search API.
	/// </para>
	/// <para>
	/// When you submit an update by query request, Elasticsearch gets a snapshot of the data stream or index when it begins processing the request and updates matching documents using internal versioning.
	/// When the versions match, the document is updated and the version number is incremented.
	/// If a document changes between the time that the snapshot is taken and the update operation is processed, it results in a version conflict and the operation fails.
	/// You can opt to count version conflicts instead of halting and returning by setting <c>conflicts</c> to <c>proceed</c>.
	/// Note that if you opt to count version conflicts, the operation could attempt to update more documents from the source than <c>max_docs</c> until it has successfully updated <c>max_docs</c> documents or it has gone through every document in the source query.
	/// </para>
	/// <para>
	/// NOTE: Documents with a version equal to 0 cannot be updated using update by query because internal versioning does not support 0 as a valid version number.
	/// </para>
	/// <para>
	/// While processing an update by query request, Elasticsearch performs multiple search requests sequentially to find all of the matching documents.
	/// A bulk update request is performed for each batch of matching documents.
	/// Any query or update failures cause the update by query request to fail and the failures are shown in the response.
	/// Any update requests that completed successfully still stick, they are not rolled back.
	/// </para>
	/// <para>
	/// <strong>Throttling update requests</strong>
	/// </para>
	/// <para>
	/// To control the rate at which update by query issues batches of update operations, you can set <c>requests_per_second</c> to any positive decimal number.
	/// This pads each batch with a wait time to throttle the rate.
	/// Set <c>requests_per_second</c> to <c>-1</c> to turn off throttling.
	/// </para>
	/// <para>
	/// Throttling uses a wait time between batches so that the internal scroll requests can be given a timeout that takes the request padding into account.
	/// The padding time is the difference between the batch size divided by the <c>requests_per_second</c> and the time spent writing.
	/// By default the batch size is 1000, so if <c>requests_per_second</c> is set to <c>500</c>:
	/// </para>
	/// <code>
	/// target_time = 1000 / 500 per second = 2 seconds
	/// wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
	/// </code>
	/// <para>
	/// Since the batch is issued as a single _bulk request, large batch sizes cause Elasticsearch to create many requests and wait before starting the next set.
	/// This is "bursty" instead of "smooth".
	/// </para>
	/// <para>
	/// <strong>Slicing</strong>
	/// </para>
	/// <para>
	/// Update by query supports sliced scroll to parallelize the update process.
	/// This can improve efficiency and provide a convenient way to break the request down into smaller parts.
	/// </para>
	/// <para>
	/// Setting <c>slices</c> to <c>auto</c> chooses a reasonable number for most data streams and indices.
	/// This setting will use one slice per shard, up to a certain limit.
	/// If there are multiple source data streams or indices, it will choose the number of slices based on the index or backing index with the smallest number of shards.
	/// </para>
	/// <para>
	/// Adding <c>slices</c> to <c>_update_by_query</c> just automates the manual process of creating sub-requests, which means it has some quirks:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// You can see these requests in the tasks APIs. These sub-requests are "child" tasks of the task for the request with slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Fetching the status of the task for the request with <c>slices</c> only contains the status of completed slices.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// These sub-requests are individually addressable for things like cancellation and rethrottling.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Rethrottling the request with <c>slices</c> will rethrottle the unfinished sub-request proportionally.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Canceling the request with slices will cancel each sub-request.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Due to the nature of slices each sub-request won't get a perfectly even portion of the documents. All documents will be addressed, but some slices may be larger than others. Expect larger slices to have a more even distribution.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Parameters like <c>requests_per_second</c> and <c>max_docs</c> on a request with slices are distributed proportionally to each sub-request. Combine that with the point above about distribution being uneven and you should conclude that using <c>max_docs</c> with <c>slices</c> might not result in exactly <c>max_docs</c> documents being updated.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Each sub-request gets a slightly different snapshot of the source data stream or index though these are all taken at approximately the same time.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// If you're slicing manually or otherwise tuning automatic slicing, keep in mind that:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// Query performance is most efficient when the number of slices is equal to the number of shards in the index or backing index. If that number is large (for example, 500), choose a lower number as too many slices hurts performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// Update performance scales linearly across available resources with the number of slices.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// Whether query or update performance dominates the runtime depends on the documents being reindexed and cluster resources.
	/// </para>
	/// <para>
	/// <strong>Update the document source</strong>
	/// </para>
	/// <para>
	/// Update by query supports scripts to update the document source.
	/// As with the update API, you can set <c>ctx.op</c> to change the operation that is performed.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "noop"</c> if your script decides that it doesn't have to make any changes.
	/// The update by query operation skips updating the document and increments the <c>noop</c> counter.
	/// </para>
	/// <para>
	/// Set <c>ctx.op = "delete"</c> if your script decides that the document should be deleted.
	/// The update by query operation deletes the document and increments the <c>deleted</c> counter.
	/// </para>
	/// <para>
	/// Update by query supports only <c>index</c>, <c>noop</c>, and <c>delete</c>.
	/// Setting <c>ctx.op</c> to anything else is an error.
	/// Setting any other field in <c>ctx</c> is an error.
	/// This API enables you to only modify the source of matching documents; you cannot move them.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryResponse> UpdateByQueryAsync(Elastic.Clients.Elasticsearch.Indices indices, Action<UpdateByQueryRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRequestDescriptor(indices);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRequestDescriptor, UpdateByQueryResponse, UpdateByQueryRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryRethrottleResponse UpdateByQueryRethrottle(UpdateByQueryRethrottleRequest request)
	{
		request.BeforeRequest();
		return DoRequest<UpdateByQueryRethrottleRequest, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(request);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryRethrottleResponse> UpdateByQueryRethrottleAsync(UpdateByQueryRethrottleRequest request, CancellationToken cancellationToken = default)
	{
		request.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRethrottleRequest, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(request, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryRethrottleResponse UpdateByQueryRethrottle(UpdateByQueryRethrottleRequestDescriptor descriptor)
	{
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRethrottleRequestDescriptor, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryRethrottleResponse UpdateByQueryRethrottle(Elastic.Clients.Elasticsearch.Id taskId)
	{
		var descriptor = new UpdateByQueryRethrottleRequestDescriptor(taskId);
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRethrottleRequestDescriptor, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	[Obsolete("Synchronous methods are deprecated and could be removed in the future.")]
	public virtual UpdateByQueryRethrottleResponse UpdateByQueryRethrottle(Elastic.Clients.Elasticsearch.Id taskId, Action<UpdateByQueryRethrottleRequestDescriptor> configureRequest)
	{
		var descriptor = new UpdateByQueryRethrottleRequestDescriptor(taskId);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequest<UpdateByQueryRethrottleRequestDescriptor, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(descriptor);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryRethrottleResponse> UpdateByQueryRethrottleAsync(UpdateByQueryRethrottleRequestDescriptor descriptor, CancellationToken cancellationToken = default)
	{
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRethrottleRequestDescriptor, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryRethrottleResponse> UpdateByQueryRethrottleAsync(Elastic.Clients.Elasticsearch.Id taskId, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRethrottleRequestDescriptor(taskId);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRethrottleRequestDescriptor, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(descriptor, cancellationToken);
	}

	/// <summary>
	/// <para>
	/// Throttle an update by query operation.
	/// </para>
	/// <para>
	/// Change the number of requests per second for a particular update by query operation.
	/// Rethrottling that speeds up the query takes effect immediately but rethrotting that slows down the query takes effect after completing the current batch to prevent scroll timeouts.
	/// </para>
	/// <para><see href="https://www.elastic.co/guide/en/elasticsearch/reference/8.17/docs-update-by-query.html#docs-update-by-query-rethrottle">Learn more about this API in the Elasticsearch documentation.</see></para>
	/// </summary>
	public virtual Task<UpdateByQueryRethrottleResponse> UpdateByQueryRethrottleAsync(Elastic.Clients.Elasticsearch.Id taskId, Action<UpdateByQueryRethrottleRequestDescriptor> configureRequest, CancellationToken cancellationToken = default)
	{
		var descriptor = new UpdateByQueryRethrottleRequestDescriptor(taskId);
		configureRequest?.Invoke(descriptor);
		descriptor.BeforeRequest();
		return DoRequestAsync<UpdateByQueryRethrottleRequestDescriptor, UpdateByQueryRethrottleResponse, UpdateByQueryRethrottleRequestParameters>(descriptor, cancellationToken);
	}
}