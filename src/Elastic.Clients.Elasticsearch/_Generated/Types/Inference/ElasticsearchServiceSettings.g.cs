// Licensed to Elasticsearch B.V under one or more agreements.
// Elasticsearch B.V licenses this file to you under the Apache 2.0 License.
// See the LICENSE file in the project root for more information.
//
// ███╗   ██╗ ██████╗ ████████╗██╗ ██████╗███████╗
// ████╗  ██║██╔═══██╗╚══██╔══╝██║██╔════╝██╔════╝
// ██╔██╗ ██║██║   ██║   ██║   ██║██║     █████╗
// ██║╚██╗██║██║   ██║   ██║   ██║██║     ██╔══╝
// ██║ ╚████║╚██████╔╝   ██║   ██║╚██████╗███████╗
// ╚═╝  ╚═══╝ ╚═════╝    ╚═╝   ╚═╝ ╚═════╝╚══════╝
// ------------------------------------------------
//
// This file is automatically generated.
// Please do not edit these files manually.
//
// ------------------------------------------------

#nullable restore

using Elastic.Clients.Elasticsearch.Fluent;
using Elastic.Clients.Elasticsearch.Serialization;
using System;
using System.Collections.Generic;
using System.Linq.Expressions;
using System.Text.Json;
using System.Text.Json.Serialization;

namespace Elastic.Clients.Elasticsearch.Inference;

public sealed partial class ElasticsearchServiceSettings
{
	/// <summary>
	/// <para>
	/// Adaptive allocations configuration details.
	/// If <c>enabled</c> is true, the number of allocations of the model is set based on the current load the process gets.
	/// When the load is high, a new model allocation is automatically created, respecting the value of <c>max_number_of_allocations</c> if it's set.
	/// When the load is low, a model allocation is automatically removed, respecting the value of <c>min_number_of_allocations</c> if it's set.
	/// If <c>enabled</c> is true, do not set the number of allocations manually.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("adaptive_allocations")]
	public Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocations? AdaptiveAllocations { get; set; }

	/// <summary>
	/// <para>
	/// The deployment identifier for a trained model deployment.
	/// When <c>deployment_id</c> is used the <c>model_id</c> is optional.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("deployment_id")]
	public string? DeploymentId { get; set; }

	/// <summary>
	/// <para>
	/// The name of the model to use for the inference task.
	/// It can be the ID of a built-in model (for example, <c>.multilingual-e5-small</c> for E5) or a text embedding model that was uploaded by using the Eland client.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("model_id")]
	public string ModelId { get; set; }

	/// <summary>
	/// <para>
	/// The total number of allocations that are assigned to the model across machine learning nodes.
	/// Increasing this value generally increases the throughput.
	/// If adaptive allocations are enabled, do not set this value because it's automatically set.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("num_allocations")]
	public int? NumAllocations { get; set; }

	/// <summary>
	/// <para>
	/// The number of threads used by each model allocation during inference.
	/// This setting generally increases the speed per inference request.
	/// The inference process is a compute-bound process; <c>threads_per_allocations</c> must not exceed the number of available allocated processors per node.
	/// The value must be a power of 2.
	/// The maximum value is 32.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("num_threads")]
	public int NumThreads { get; set; }
}

public sealed partial class ElasticsearchServiceSettingsDescriptor : SerializableDescriptor<ElasticsearchServiceSettingsDescriptor>
{
	internal ElasticsearchServiceSettingsDescriptor(Action<ElasticsearchServiceSettingsDescriptor> configure) => configure.Invoke(this);

	public ElasticsearchServiceSettingsDescriptor() : base()
	{
	}

	private Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocations? AdaptiveAllocationsValue { get; set; }
	private Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor AdaptiveAllocationsDescriptor { get; set; }
	private Action<Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor> AdaptiveAllocationsDescriptorAction { get; set; }
	private string? DeploymentIdValue { get; set; }
	private string ModelIdValue { get; set; }
	private int? NumAllocationsValue { get; set; }
	private int NumThreadsValue { get; set; }

	/// <summary>
	/// <para>
	/// Adaptive allocations configuration details.
	/// If <c>enabled</c> is true, the number of allocations of the model is set based on the current load the process gets.
	/// When the load is high, a new model allocation is automatically created, respecting the value of <c>max_number_of_allocations</c> if it's set.
	/// When the load is low, a model allocation is automatically removed, respecting the value of <c>min_number_of_allocations</c> if it's set.
	/// If <c>enabled</c> is true, do not set the number of allocations manually.
	/// </para>
	/// </summary>
	public ElasticsearchServiceSettingsDescriptor AdaptiveAllocations(Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocations? adaptiveAllocations)
	{
		AdaptiveAllocationsDescriptor = null;
		AdaptiveAllocationsDescriptorAction = null;
		AdaptiveAllocationsValue = adaptiveAllocations;
		return Self;
	}

	public ElasticsearchServiceSettingsDescriptor AdaptiveAllocations(Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor descriptor)
	{
		AdaptiveAllocationsValue = null;
		AdaptiveAllocationsDescriptorAction = null;
		AdaptiveAllocationsDescriptor = descriptor;
		return Self;
	}

	public ElasticsearchServiceSettingsDescriptor AdaptiveAllocations(Action<Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor> configure)
	{
		AdaptiveAllocationsValue = null;
		AdaptiveAllocationsDescriptor = null;
		AdaptiveAllocationsDescriptorAction = configure;
		return Self;
	}

	/// <summary>
	/// <para>
	/// The deployment identifier for a trained model deployment.
	/// When <c>deployment_id</c> is used the <c>model_id</c> is optional.
	/// </para>
	/// </summary>
	public ElasticsearchServiceSettingsDescriptor DeploymentId(string? deploymentId)
	{
		DeploymentIdValue = deploymentId;
		return Self;
	}

	/// <summary>
	/// <para>
	/// The name of the model to use for the inference task.
	/// It can be the ID of a built-in model (for example, <c>.multilingual-e5-small</c> for E5) or a text embedding model that was uploaded by using the Eland client.
	/// </para>
	/// </summary>
	public ElasticsearchServiceSettingsDescriptor ModelId(string modelId)
	{
		ModelIdValue = modelId;
		return Self;
	}

	/// <summary>
	/// <para>
	/// The total number of allocations that are assigned to the model across machine learning nodes.
	/// Increasing this value generally increases the throughput.
	/// If adaptive allocations are enabled, do not set this value because it's automatically set.
	/// </para>
	/// </summary>
	public ElasticsearchServiceSettingsDescriptor NumAllocations(int? numAllocations)
	{
		NumAllocationsValue = numAllocations;
		return Self;
	}

	/// <summary>
	/// <para>
	/// The number of threads used by each model allocation during inference.
	/// This setting generally increases the speed per inference request.
	/// The inference process is a compute-bound process; <c>threads_per_allocations</c> must not exceed the number of available allocated processors per node.
	/// The value must be a power of 2.
	/// The maximum value is 32.
	/// </para>
	/// </summary>
	public ElasticsearchServiceSettingsDescriptor NumThreads(int numThreads)
	{
		NumThreadsValue = numThreads;
		return Self;
	}

	protected override void Serialize(Utf8JsonWriter writer, JsonSerializerOptions options, IElasticsearchClientSettings settings)
	{
		writer.WriteStartObject();
		if (AdaptiveAllocationsDescriptor is not null)
		{
			writer.WritePropertyName("adaptive_allocations");
			JsonSerializer.Serialize(writer, AdaptiveAllocationsDescriptor, options);
		}
		else if (AdaptiveAllocationsDescriptorAction is not null)
		{
			writer.WritePropertyName("adaptive_allocations");
			JsonSerializer.Serialize(writer, new Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor(AdaptiveAllocationsDescriptorAction), options);
		}
		else if (AdaptiveAllocationsValue is not null)
		{
			writer.WritePropertyName("adaptive_allocations");
			JsonSerializer.Serialize(writer, AdaptiveAllocationsValue, options);
		}

		if (!string.IsNullOrEmpty(DeploymentIdValue))
		{
			writer.WritePropertyName("deployment_id");
			writer.WriteStringValue(DeploymentIdValue);
		}

		writer.WritePropertyName("model_id");
		writer.WriteStringValue(ModelIdValue);
		if (NumAllocationsValue.HasValue)
		{
			writer.WritePropertyName("num_allocations");
			writer.WriteNumberValue(NumAllocationsValue.Value);
		}

		writer.WritePropertyName("num_threads");
		writer.WriteNumberValue(NumThreadsValue);
		writer.WriteEndObject();
	}
}