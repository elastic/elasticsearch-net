// Licensed to Elasticsearch B.V under one or more agreements.
// Elasticsearch B.V licenses this file to you under the Apache 2.0 License.
// See the LICENSE file in the project root for more information.
//
// ███╗   ██╗ ██████╗ ████████╗██╗ ██████╗███████╗
// ████╗  ██║██╔═══██╗╚══██╔══╝██║██╔════╝██╔════╝
// ██╔██╗ ██║██║   ██║   ██║   ██║██║     █████╗
// ██║╚██╗██║██║   ██║   ██║   ██║██║     ██╔══╝
// ██║ ╚████║╚██████╔╝   ██║   ██║╚██████╗███████╗
// ╚═╝  ╚═══╝ ╚═════╝    ╚═╝   ╚═╝ ╚═════╝╚══════╝
// ------------------------------------------------
//
// This file is automatically generated.
// Please do not edit these files manually.
//
// ------------------------------------------------

#nullable restore

using System;
using System.Linq;
using Elastic.Clients.Elasticsearch.Serialization;

namespace Elastic.Clients.Elasticsearch.Inference;

internal sealed partial class ElserServiceSettingsConverter : System.Text.Json.Serialization.JsonConverter<Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings>
{
	private static readonly System.Text.Json.JsonEncodedText PropAdaptiveAllocations = System.Text.Json.JsonEncodedText.Encode("adaptive_allocations");
	private static readonly System.Text.Json.JsonEncodedText PropNumAllocations = System.Text.Json.JsonEncodedText.Encode("num_allocations");
	private static readonly System.Text.Json.JsonEncodedText PropNumThreads = System.Text.Json.JsonEncodedText.Encode("num_threads");

	public override Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings Read(ref System.Text.Json.Utf8JsonReader reader, System.Type typeToConvert, System.Text.Json.JsonSerializerOptions options)
	{
		reader.ValidateToken(System.Text.Json.JsonTokenType.StartObject);
		LocalJsonValue<Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocations?> propAdaptiveAllocations = default;
		LocalJsonValue<int> propNumAllocations = default;
		LocalJsonValue<int> propNumThreads = default;
		while (reader.Read() && reader.TokenType is System.Text.Json.JsonTokenType.PropertyName)
		{
			if (propAdaptiveAllocations.TryReadProperty(ref reader, options, PropAdaptiveAllocations, null))
			{
				continue;
			}

			if (propNumAllocations.TryReadProperty(ref reader, options, PropNumAllocations, null))
			{
				continue;
			}

			if (propNumThreads.TryReadProperty(ref reader, options, PropNumThreads, null))
			{
				continue;
			}

			if (options.UnmappedMemberHandling is System.Text.Json.Serialization.JsonUnmappedMemberHandling.Skip)
			{
				reader.Skip();
				continue;
			}

			throw new System.Text.Json.JsonException($"Unknown JSON property '{reader.GetString()}' for type '{typeToConvert.Name}'.");
		}

		reader.ValidateToken(System.Text.Json.JsonTokenType.EndObject);
		return new Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel.Instance)
		{
			AdaptiveAllocations = propAdaptiveAllocations.Value,
			NumAllocations = propNumAllocations.Value,
			NumThreads = propNumThreads.Value
		};
	}

	public override void Write(System.Text.Json.Utf8JsonWriter writer, Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings value, System.Text.Json.JsonSerializerOptions options)
	{
		writer.WriteStartObject();
		writer.WriteProperty(options, PropAdaptiveAllocations, value.AdaptiveAllocations, null, null);
		writer.WriteProperty(options, PropNumAllocations, value.NumAllocations, null, null);
		writer.WriteProperty(options, PropNumThreads, value.NumThreads, null, null);
		writer.WriteEndObject();
	}
}

[System.Text.Json.Serialization.JsonConverter(typeof(Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsConverter))]
public sealed partial class ElserServiceSettings
{
	[System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
	public ElserServiceSettings(int numAllocations, int numThreads)
	{
		NumAllocations = numAllocations;
		NumThreads = numThreads;
	}
#if NET7_0_OR_GREATER
	public ElserServiceSettings()
	{
	}
#endif
#if !NET7_0_OR_GREATER
	[System.Obsolete("The type contains required properties that must be initialized. Please use an alternative constructor to ensure all required values are properly set.")]
	public ElserServiceSettings()
	{
	}
#endif
	[System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
	internal ElserServiceSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel sentinel)
	{
		_ = sentinel;
	}

	/// <summary>
	/// <para>
	/// Adaptive allocations configuration details.
	/// If <c>enabled</c> is true, the number of allocations of the model is set based on the current load the process gets.
	/// When the load is high, a new model allocation is automatically created, respecting the value of <c>max_number_of_allocations</c> if it's set.
	/// When the load is low, a model allocation is automatically removed, respecting the value of <c>min_number_of_allocations</c> if it's set.
	/// If <c>enabled</c> is true, do not set the number of allocations manually.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocations? AdaptiveAllocations { get; set; }

	/// <summary>
	/// <para>
	/// The total number of allocations this model is assigned across machine learning nodes.
	/// Increasing this value generally increases the throughput.
	/// If adaptive allocations is enabled, do not set this value because it's automatically set.
	/// </para>
	/// </summary>
	public
#if NET7_0_OR_GREATER
	required
#endif
	int NumAllocations { get; set; }

	/// <summary>
	/// <para>
	/// The number of threads used by each model allocation during inference.
	/// Increasing this value generally increases the speed per inference request.
	/// The inference process is a compute-bound process; <c>threads_per_allocations</c> must not exceed the number of available allocated processors per node.
	/// The value must be a power of 2.
	/// The maximum value is 32.
	/// </para>
	/// <para>
	/// info
	/// If you want to optimize your ELSER endpoint for ingest, set the number of threads to 1. If you want to optimize your ELSER endpoint for search, set the number of threads to greater than 1.
	/// </para>
	/// </summary>
	public
#if NET7_0_OR_GREATER
	required
#endif
	int NumThreads { get; set; }
}

public readonly partial struct ElserServiceSettingsDescriptor
{
	internal Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings Instance { get; init; }

	[System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
	public ElserServiceSettingsDescriptor(Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings instance)
	{
		Instance = instance;
	}

	[System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
	public ElserServiceSettingsDescriptor()
	{
		Instance = new Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel.Instance);
	}

	public static explicit operator Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor(Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings instance) => new Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor(instance);
	public static implicit operator Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings(Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor descriptor) => descriptor.Instance;

	/// <summary>
	/// <para>
	/// Adaptive allocations configuration details.
	/// If <c>enabled</c> is true, the number of allocations of the model is set based on the current load the process gets.
	/// When the load is high, a new model allocation is automatically created, respecting the value of <c>max_number_of_allocations</c> if it's set.
	/// When the load is low, a model allocation is automatically removed, respecting the value of <c>min_number_of_allocations</c> if it's set.
	/// If <c>enabled</c> is true, do not set the number of allocations manually.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor AdaptiveAllocations(Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocations? value)
	{
		Instance.AdaptiveAllocations = value;
		return this;
	}

	/// <summary>
	/// <para>
	/// Adaptive allocations configuration details.
	/// If <c>enabled</c> is true, the number of allocations of the model is set based on the current load the process gets.
	/// When the load is high, a new model allocation is automatically created, respecting the value of <c>max_number_of_allocations</c> if it's set.
	/// When the load is low, a model allocation is automatically removed, respecting the value of <c>min_number_of_allocations</c> if it's set.
	/// If <c>enabled</c> is true, do not set the number of allocations manually.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor AdaptiveAllocations()
	{
		Instance.AdaptiveAllocations = Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor.Build(null);
		return this;
	}

	/// <summary>
	/// <para>
	/// Adaptive allocations configuration details.
	/// If <c>enabled</c> is true, the number of allocations of the model is set based on the current load the process gets.
	/// When the load is high, a new model allocation is automatically created, respecting the value of <c>max_number_of_allocations</c> if it's set.
	/// When the load is low, a model allocation is automatically removed, respecting the value of <c>min_number_of_allocations</c> if it's set.
	/// If <c>enabled</c> is true, do not set the number of allocations manually.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor AdaptiveAllocations(System.Action<Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor>? action)
	{
		Instance.AdaptiveAllocations = Elastic.Clients.Elasticsearch.Inference.AdaptiveAllocationsDescriptor.Build(action);
		return this;
	}

	/// <summary>
	/// <para>
	/// The total number of allocations this model is assigned across machine learning nodes.
	/// Increasing this value generally increases the throughput.
	/// If adaptive allocations is enabled, do not set this value because it's automatically set.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor NumAllocations(int value)
	{
		Instance.NumAllocations = value;
		return this;
	}

	/// <summary>
	/// <para>
	/// The number of threads used by each model allocation during inference.
	/// Increasing this value generally increases the speed per inference request.
	/// The inference process is a compute-bound process; <c>threads_per_allocations</c> must not exceed the number of available allocated processors per node.
	/// The value must be a power of 2.
	/// The maximum value is 32.
	/// </para>
	/// <para>
	/// info
	/// If you want to optimize your ELSER endpoint for ingest, set the number of threads to 1. If you want to optimize your ELSER endpoint for search, set the number of threads to greater than 1.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor NumThreads(int value)
	{
		Instance.NumThreads = value;
		return this;
	}

	[System.Runtime.CompilerServices.MethodImpl(System.Runtime.CompilerServices.MethodImplOptions.AggressiveInlining)]
	internal static Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings Build(System.Action<Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor> action)
	{
		var builder = new Elastic.Clients.Elasticsearch.Inference.ElserServiceSettingsDescriptor(new Elastic.Clients.Elasticsearch.Inference.ElserServiceSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel.Instance));
		action.Invoke(builder);
		return builder.Instance;
	}
}