// Licensed to Elasticsearch B.V under one or more agreements.
// Elasticsearch B.V licenses this file to you under the Apache 2.0 License.
// See the LICENSE file in the project root for more information.
//
// ███╗   ██╗ ██████╗ ████████╗██╗ ██████╗███████╗
// ████╗  ██║██╔═══██╗╚══██╔══╝██║██╔════╝██╔════╝
// ██╔██╗ ██║██║   ██║   ██║   ██║██║     █████╗
// ██║╚██╗██║██║   ██║   ██║   ██║██║     ██╔══╝
// ██║ ╚████║╚██████╔╝   ██║   ██║╚██████╗███████╗
// ╚═╝  ╚═══╝ ╚═════╝    ╚═╝   ╚═╝ ╚═════╝╚══════╝
// ------------------------------------------------
//
// This file is automatically generated.
// Please do not edit these files manually.
//
// ------------------------------------------------

#nullable restore

using System;
using System.Linq;
using Elastic.Clients.Elasticsearch.Serialization;

namespace Elastic.Clients.Elasticsearch.Inference;

[System.Text.Json.Serialization.JsonConverter(typeof(Elastic.Clients.Elasticsearch.Inference.Json.NvidiaTaskSettingsConverter))]
public sealed partial class NvidiaTaskSettings
{
	public NvidiaTaskSettings()
	{
	}

	[System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
	internal NvidiaTaskSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel sentinel)
	{
		_ = sentinel;
	}

	/// <summary>
	/// <para>
	/// For a <c>text_embedding</c> task, type of input sent to the Nvidia endpoint.
	/// Valid values are:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>ingest</c>: Mapped to Nvidia's <c>passage</c> value in request. Used when generating embeddings during indexing.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>search</c>: Mapped to Nvidia's <c>query</c> value in request. Used when generating embeddings during querying.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// IMPORTANT: For Nvidia endpoints, if the <c>input_type</c> field is not specified, it defaults to <c>query</c>.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.NvidiaInputType? InputType { get; set; }

	/// <summary>
	/// <para>
	/// For a <c>text_embedding</c> task, the method used by the Nvidia model to handle inputs longer than the maximum token length.
	/// Valid values are:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>END</c>: When the input exceeds the maximum input token length, the end of the input is discarded.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>NONE</c>: When the input exceeds the maximum input token length, an error is returned.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>START</c>: When the input exceeds the maximum input token length, the start of the input is discarded.
	/// </para>
	/// </item>
	/// </list>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.CohereTruncateType? Truncate { get; set; }
}

public readonly partial struct NvidiaTaskSettingsDescriptor
{
	internal Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings Instance { get; init; }

	[System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
	public NvidiaTaskSettingsDescriptor(Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings instance)
	{
		Instance = instance;
	}

	[System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
	public NvidiaTaskSettingsDescriptor()
	{
		Instance = new Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel.Instance);
	}

	public static explicit operator Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettingsDescriptor(Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings instance) => new Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettingsDescriptor(instance);
	public static implicit operator Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings(Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettingsDescriptor descriptor) => descriptor.Instance;

	/// <summary>
	/// <para>
	/// For a <c>text_embedding</c> task, type of input sent to the Nvidia endpoint.
	/// Valid values are:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>ingest</c>: Mapped to Nvidia's <c>passage</c> value in request. Used when generating embeddings during indexing.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>search</c>: Mapped to Nvidia's <c>query</c> value in request. Used when generating embeddings during querying.
	/// </para>
	/// </item>
	/// </list>
	/// <para>
	/// IMPORTANT: For Nvidia endpoints, if the <c>input_type</c> field is not specified, it defaults to <c>query</c>.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettingsDescriptor InputType(Elastic.Clients.Elasticsearch.Inference.NvidiaInputType? value)
	{
		Instance.InputType = value;
		return this;
	}

	/// <summary>
	/// <para>
	/// For a <c>text_embedding</c> task, the method used by the Nvidia model to handle inputs longer than the maximum token length.
	/// Valid values are:
	/// </para>
	/// <list type="bullet">
	/// <item>
	/// <para>
	/// <c>END</c>: When the input exceeds the maximum input token length, the end of the input is discarded.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>NONE</c>: When the input exceeds the maximum input token length, an error is returned.
	/// </para>
	/// </item>
	/// <item>
	/// <para>
	/// <c>START</c>: When the input exceeds the maximum input token length, the start of the input is discarded.
	/// </para>
	/// </item>
	/// </list>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettingsDescriptor Truncate(Elastic.Clients.Elasticsearch.Inference.CohereTruncateType? value)
	{
		Instance.Truncate = value;
		return this;
	}

	[System.Runtime.CompilerServices.MethodImpl(System.Runtime.CompilerServices.MethodImplOptions.AggressiveInlining)]
	internal static Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings Build(System.Action<Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettingsDescriptor>? action)
	{
		if (action is null)
		{
			return new Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel.Instance);
		}

		var builder = new Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettingsDescriptor(new Elastic.Clients.Elasticsearch.Inference.NvidiaTaskSettings(Elastic.Clients.Elasticsearch.Serialization.JsonConstructorSentinel.Instance));
		action.Invoke(builder);
		return builder.Instance;
	}
}