// Licensed to Elasticsearch B.V under one or more agreements.
// Elasticsearch B.V licenses this file to you under the Apache 2.0 License.
// See the LICENSE file in the project root for more information.
//
// ███╗   ██╗ ██████╗ ████████╗██╗ ██████╗███████╗
// ████╗  ██║██╔═══██╗╚══██╔══╝██║██╔════╝██╔════╝
// ██╔██╗ ██║██║   ██║   ██║   ██║██║     █████╗
// ██║╚██╗██║██║   ██║   ██║   ██║██║     ██╔══╝
// ██║ ╚████║╚██████╔╝   ██║   ██║╚██████╗███████╗
// ╚═╝  ╚═══╝ ╚═════╝    ╚═╝   ╚═╝ ╚═════╝╚══════╝
// ------------------------------------------------
//
// This file is automatically generated.
// Please do not edit these files manually.
//
// ------------------------------------------------

#nullable restore

using Elastic.Clients.Elasticsearch.Fluent;
using Elastic.Clients.Elasticsearch.Serialization;
using System;
using System.Collections.Generic;
using System.Linq.Expressions;
using System.Text.Json;
using System.Text.Json.Serialization;

namespace Elastic.Clients.Elasticsearch.Inference;

public sealed partial class AzureAiStudioTaskSettings
{
	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, instruct the inference process to perform sampling.
	/// It has no effect unless <c>temperature</c> or <c>top_p</c> is specified.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("do_sample")]
	public float? DoSample { get; set; }

	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, provide a hint for the maximum number of output tokens to be generated.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("max_new_tokens")]
	public int? MaxNewTokens { get; set; }

	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, control the apparent creativity of generated completions with a sampling temperature.
	/// It must be a number in the range of 0.0 to 2.0.
	/// It should not be used if <c>top_p</c> is specified.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("temperature")]
	public float? Temperature { get; set; }

	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, make the model consider the results of the tokens with nucleus sampling probability.
	/// It is an alternative value to <c>temperature</c> and must be a number in the range of 0.0 to 2.0.
	/// It should not be used if <c>temperature</c> is specified.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("top_p")]
	public float? TopP { get; set; }

	/// <summary>
	/// <para>
	/// For a <c>text_embedding</c> task, specify the user issuing the request.
	/// This information can be used for abuse detection.
	/// </para>
	/// </summary>
	[JsonInclude, JsonPropertyName("user")]
	public string? User { get; set; }
}

public sealed partial class AzureAiStudioTaskSettingsDescriptor : SerializableDescriptor<AzureAiStudioTaskSettingsDescriptor>
{
	internal AzureAiStudioTaskSettingsDescriptor(Action<AzureAiStudioTaskSettingsDescriptor> configure) => configure.Invoke(this);

	public AzureAiStudioTaskSettingsDescriptor() : base()
	{
	}

	private float? DoSampleValue { get; set; }
	private int? MaxNewTokensValue { get; set; }
	private float? TemperatureValue { get; set; }
	private float? TopPValue { get; set; }
	private string? UserValue { get; set; }

	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, instruct the inference process to perform sampling.
	/// It has no effect unless <c>temperature</c> or <c>top_p</c> is specified.
	/// </para>
	/// </summary>
	public AzureAiStudioTaskSettingsDescriptor DoSample(float? doSample)
	{
		DoSampleValue = doSample;
		return Self;
	}

	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, provide a hint for the maximum number of output tokens to be generated.
	/// </para>
	/// </summary>
	public AzureAiStudioTaskSettingsDescriptor MaxNewTokens(int? maxNewTokens)
	{
		MaxNewTokensValue = maxNewTokens;
		return Self;
	}

	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, control the apparent creativity of generated completions with a sampling temperature.
	/// It must be a number in the range of 0.0 to 2.0.
	/// It should not be used if <c>top_p</c> is specified.
	/// </para>
	/// </summary>
	public AzureAiStudioTaskSettingsDescriptor Temperature(float? temperature)
	{
		TemperatureValue = temperature;
		return Self;
	}

	/// <summary>
	/// <para>
	/// For a <c>completion</c> task, make the model consider the results of the tokens with nucleus sampling probability.
	/// It is an alternative value to <c>temperature</c> and must be a number in the range of 0.0 to 2.0.
	/// It should not be used if <c>temperature</c> is specified.
	/// </para>
	/// </summary>
	public AzureAiStudioTaskSettingsDescriptor TopP(float? topP)
	{
		TopPValue = topP;
		return Self;
	}

	/// <summary>
	/// <para>
	/// For a <c>text_embedding</c> task, specify the user issuing the request.
	/// This information can be used for abuse detection.
	/// </para>
	/// </summary>
	public AzureAiStudioTaskSettingsDescriptor User(string? user)
	{
		UserValue = user;
		return Self;
	}

	protected override void Serialize(Utf8JsonWriter writer, JsonSerializerOptions options, IElasticsearchClientSettings settings)
	{
		writer.WriteStartObject();
		if (DoSampleValue.HasValue)
		{
			writer.WritePropertyName("do_sample");
			writer.WriteNumberValue(DoSampleValue.Value);
		}

		if (MaxNewTokensValue.HasValue)
		{
			writer.WritePropertyName("max_new_tokens");
			writer.WriteNumberValue(MaxNewTokensValue.Value);
		}

		if (TemperatureValue.HasValue)
		{
			writer.WritePropertyName("temperature");
			writer.WriteNumberValue(TemperatureValue.Value);
		}

		if (TopPValue.HasValue)
		{
			writer.WritePropertyName("top_p");
			writer.WriteNumberValue(TopPValue.Value);
		}

		if (!string.IsNullOrEmpty(UserValue))
		{
			writer.WritePropertyName("user");
			writer.WriteStringValue(UserValue);
		}

		writer.WriteEndObject();
	}
}