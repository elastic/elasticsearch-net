// Licensed to Elasticsearch B.V under one or more agreements.
// Elasticsearch B.V licenses this file to you under the Apache 2.0 License.
// See the LICENSE file in the project root for more information.
//
// ███╗   ██╗ ██████╗ ████████╗██╗ ██████╗███████╗
// ████╗  ██║██╔═══██╗╚══██╔══╝██║██╔════╝██╔════╝
// ██╔██╗ ██║██║   ██║   ██║   ██║██║     █████╗
// ██║╚██╗██║██║   ██║   ██║   ██║██║     ██╔══╝
// ██║ ╚████║╚██████╔╝   ██║   ██║╚██████╗███████╗
// ╚═╝  ╚═══╝ ╚═════╝    ╚═╝   ╚═╝ ╚═════╝╚══════╝
// ------------------------------------------------
//
// This file is automatically generated.
// Please do not edit these files manually.
//
// ------------------------------------------------

#nullable restore

using Elastic.Clients.Elasticsearch.Fluent;
using Elastic.Clients.Elasticsearch.Serialization;
using System;
using System.Collections.Generic;
using System.Linq.Expressions;
using System.Text.Json;
using System.Text.Json.Serialization;

namespace Elastic.Clients.Elasticsearch.MachineLearning;

internal sealed partial class DataframeAnalysisClassificationConverter : System.Text.Json.Serialization.JsonConverter<DataframeAnalysisClassification>
{
	private static readonly System.Text.Json.JsonEncodedText PropAlpha = System.Text.Json.JsonEncodedText.Encode("alpha");
	private static readonly System.Text.Json.JsonEncodedText PropClassAssignmentObjective = System.Text.Json.JsonEncodedText.Encode("class_assignment_objective");
	private static readonly System.Text.Json.JsonEncodedText PropDependentVariable = System.Text.Json.JsonEncodedText.Encode("dependent_variable");
	private static readonly System.Text.Json.JsonEncodedText PropDownsampleFactor = System.Text.Json.JsonEncodedText.Encode("downsample_factor");
	private static readonly System.Text.Json.JsonEncodedText PropEarlyStoppingEnabled = System.Text.Json.JsonEncodedText.Encode("early_stopping_enabled");
	private static readonly System.Text.Json.JsonEncodedText PropEta = System.Text.Json.JsonEncodedText.Encode("eta");
	private static readonly System.Text.Json.JsonEncodedText PropEtaGrowthRatePerTree = System.Text.Json.JsonEncodedText.Encode("eta_growth_rate_per_tree");
	private static readonly System.Text.Json.JsonEncodedText PropFeatureBagFraction = System.Text.Json.JsonEncodedText.Encode("feature_bag_fraction");
	private static readonly System.Text.Json.JsonEncodedText PropFeatureProcessors = System.Text.Json.JsonEncodedText.Encode("feature_processors");
	private static readonly System.Text.Json.JsonEncodedText PropGamma = System.Text.Json.JsonEncodedText.Encode("gamma");
	private static readonly System.Text.Json.JsonEncodedText PropLambda = System.Text.Json.JsonEncodedText.Encode("lambda");
	private static readonly System.Text.Json.JsonEncodedText PropMaxOptimizationRoundsPerHyperparameter = System.Text.Json.JsonEncodedText.Encode("max_optimization_rounds_per_hyperparameter");
	private static readonly System.Text.Json.JsonEncodedText PropMaxTrees = System.Text.Json.JsonEncodedText.Encode("max_trees");
	private static readonly System.Text.Json.JsonEncodedText PropMaxTrees1 = System.Text.Json.JsonEncodedText.Encode("maximum_number_trees");
	private static readonly System.Text.Json.JsonEncodedText PropNumTopClasses = System.Text.Json.JsonEncodedText.Encode("num_top_classes");
	private static readonly System.Text.Json.JsonEncodedText PropNumTopFeatureImportanceValues = System.Text.Json.JsonEncodedText.Encode("num_top_feature_importance_values");
	private static readonly System.Text.Json.JsonEncodedText PropPredictionFieldName = System.Text.Json.JsonEncodedText.Encode("prediction_field_name");
	private static readonly System.Text.Json.JsonEncodedText PropRandomizeSeed = System.Text.Json.JsonEncodedText.Encode("randomize_seed");
	private static readonly System.Text.Json.JsonEncodedText PropSoftTreeDepthLimit = System.Text.Json.JsonEncodedText.Encode("soft_tree_depth_limit");
	private static readonly System.Text.Json.JsonEncodedText PropSoftTreeDepthTolerance = System.Text.Json.JsonEncodedText.Encode("soft_tree_depth_tolerance");
	private static readonly System.Text.Json.JsonEncodedText PropTrainingPercent = System.Text.Json.JsonEncodedText.Encode("training_percent");

	public override DataframeAnalysisClassification Read(ref System.Text.Json.Utf8JsonReader reader, System.Type typeToConvert, System.Text.Json.JsonSerializerOptions options)
	{
		reader.ValidateToken(System.Text.Json.JsonTokenType.StartObject);
		LocalJsonValue<double?> propAlpha = default;
		LocalJsonValue<string?> propClassAssignmentObjective = default;
		LocalJsonValue<string> propDependentVariable = default;
		LocalJsonValue<double?> propDownsampleFactor = default;
		LocalJsonValue<bool?> propEarlyStoppingEnabled = default;
		LocalJsonValue<double?> propEta = default;
		LocalJsonValue<double?> propEtaGrowthRatePerTree = default;
		LocalJsonValue<double?> propFeatureBagFraction = default;
		LocalJsonValue<ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>?> propFeatureProcessors = default;
		LocalJsonValue<double?> propGamma = default;
		LocalJsonValue<double?> propLambda = default;
		LocalJsonValue<int?> propMaxOptimizationRoundsPerHyperparameter = default;
		LocalJsonValue<int?> propMaxTrees = default;
		LocalJsonValue<int?> propNumTopClasses = default;
		LocalJsonValue<int?> propNumTopFeatureImportanceValues = default;
		LocalJsonValue<Elastic.Clients.Elasticsearch.Field?> propPredictionFieldName = default;
		LocalJsonValue<double?> propRandomizeSeed = default;
		LocalJsonValue<int?> propSoftTreeDepthLimit = default;
		LocalJsonValue<double?> propSoftTreeDepthTolerance = default;
		LocalJsonValue<double?> propTrainingPercent = default;
		while (reader.Read() && reader.TokenType is System.Text.Json.JsonTokenType.PropertyName)
		{
			if (propAlpha.TryReadProperty(ref reader, options, PropAlpha, null))
			{
				continue;
			}

			if (propClassAssignmentObjective.TryReadProperty(ref reader, options, PropClassAssignmentObjective, null))
			{
				continue;
			}

			if (propDependentVariable.TryReadProperty(ref reader, options, PropDependentVariable, null))
			{
				continue;
			}

			if (propDownsampleFactor.TryReadProperty(ref reader, options, PropDownsampleFactor, null))
			{
				continue;
			}

			if (propEarlyStoppingEnabled.TryReadProperty(ref reader, options, PropEarlyStoppingEnabled, null))
			{
				continue;
			}

			if (propEta.TryReadProperty(ref reader, options, PropEta, null))
			{
				continue;
			}

			if (propEtaGrowthRatePerTree.TryReadProperty(ref reader, options, PropEtaGrowthRatePerTree, null))
			{
				continue;
			}

			if (propFeatureBagFraction.TryReadProperty(ref reader, options, PropFeatureBagFraction, null))
			{
				continue;
			}

			if (propFeatureProcessors.TryReadProperty(ref reader, options, PropFeatureProcessors, static ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>? (ref System.Text.Json.Utf8JsonReader r, System.Text.Json.JsonSerializerOptions o) => r.ReadCollectionValue<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>(o, null)))
			{
				continue;
			}

			if (propGamma.TryReadProperty(ref reader, options, PropGamma, null))
			{
				continue;
			}

			if (propLambda.TryReadProperty(ref reader, options, PropLambda, null))
			{
				continue;
			}

			if (propMaxOptimizationRoundsPerHyperparameter.TryReadProperty(ref reader, options, PropMaxOptimizationRoundsPerHyperparameter, null))
			{
				continue;
			}

			if (propMaxTrees.TryReadProperty(ref reader, options, PropMaxTrees, null) || propMaxTrees.TryReadProperty(ref reader, options, PropMaxTrees1, null))
			{
				continue;
			}

			if (propNumTopClasses.TryReadProperty(ref reader, options, PropNumTopClasses, null))
			{
				continue;
			}

			if (propNumTopFeatureImportanceValues.TryReadProperty(ref reader, options, PropNumTopFeatureImportanceValues, null))
			{
				continue;
			}

			if (propPredictionFieldName.TryReadProperty(ref reader, options, PropPredictionFieldName, null))
			{
				continue;
			}

			if (propRandomizeSeed.TryReadProperty(ref reader, options, PropRandomizeSeed, null))
			{
				continue;
			}

			if (propSoftTreeDepthLimit.TryReadProperty(ref reader, options, PropSoftTreeDepthLimit, null))
			{
				continue;
			}

			if (propSoftTreeDepthTolerance.TryReadProperty(ref reader, options, PropSoftTreeDepthTolerance, null))
			{
				continue;
			}

			if (propTrainingPercent.TryReadProperty(ref reader, options, PropTrainingPercent, null))
			{
				continue;
			}

			throw new System.Text.Json.JsonException($"Unknown JSON property '{reader.GetString()}' for type '{typeToConvert.Name}'.");
		}

		reader.ValidateToken(System.Text.Json.JsonTokenType.EndObject);
		return new DataframeAnalysisClassification
		{
			Alpha = propAlpha.Value
,
			ClassAssignmentObjective = propClassAssignmentObjective.Value
,
			DependentVariable = propDependentVariable.Value
,
			DownsampleFactor = propDownsampleFactor.Value
,
			EarlyStoppingEnabled = propEarlyStoppingEnabled.Value
,
			Eta = propEta.Value
,
			EtaGrowthRatePerTree = propEtaGrowthRatePerTree.Value
,
			FeatureBagFraction = propFeatureBagFraction.Value
,
			FeatureProcessors = propFeatureProcessors.Value
,
			Gamma = propGamma.Value
,
			Lambda = propLambda.Value
,
			MaxOptimizationRoundsPerHyperparameter = propMaxOptimizationRoundsPerHyperparameter.Value
,
			MaxTrees = propMaxTrees.Value
,
			NumTopClasses = propNumTopClasses.Value
,
			NumTopFeatureImportanceValues = propNumTopFeatureImportanceValues.Value
,
			PredictionFieldName = propPredictionFieldName.Value
,
			RandomizeSeed = propRandomizeSeed.Value
,
			SoftTreeDepthLimit = propSoftTreeDepthLimit.Value
,
			SoftTreeDepthTolerance = propSoftTreeDepthTolerance.Value
,
			TrainingPercent = propTrainingPercent.Value
		};
	}

	public override void Write(System.Text.Json.Utf8JsonWriter writer, DataframeAnalysisClassification value, System.Text.Json.JsonSerializerOptions options)
	{
		writer.WriteStartObject();
		writer.WriteProperty(options, PropAlpha, value.Alpha, null, null);
		writer.WriteProperty(options, PropClassAssignmentObjective, value.ClassAssignmentObjective, null, null);
		writer.WriteProperty(options, PropDependentVariable, value.DependentVariable, null, null);
		writer.WriteProperty(options, PropDownsampleFactor, value.DownsampleFactor, null, null);
		writer.WriteProperty(options, PropEarlyStoppingEnabled, value.EarlyStoppingEnabled, null, null);
		writer.WriteProperty(options, PropEta, value.Eta, null, null);
		writer.WriteProperty(options, PropEtaGrowthRatePerTree, value.EtaGrowthRatePerTree, null, null);
		writer.WriteProperty(options, PropFeatureBagFraction, value.FeatureBagFraction, null, null);
		writer.WriteProperty(options, PropFeatureProcessors, value.FeatureProcessors, null, static (System.Text.Json.Utf8JsonWriter w, System.Text.Json.JsonSerializerOptions o, ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>? v) => w.WriteCollectionValue<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>(o, v, null));
		writer.WriteProperty(options, PropGamma, value.Gamma, null, null);
		writer.WriteProperty(options, PropLambda, value.Lambda, null, null);
		writer.WriteProperty(options, PropMaxOptimizationRoundsPerHyperparameter, value.MaxOptimizationRoundsPerHyperparameter, null, null);
		writer.WriteProperty(options, PropMaxTrees, value.MaxTrees, null, null);
		writer.WriteProperty(options, PropNumTopClasses, value.NumTopClasses, null, null);
		writer.WriteProperty(options, PropNumTopFeatureImportanceValues, value.NumTopFeatureImportanceValues, null, null);
		writer.WriteProperty(options, PropPredictionFieldName, value.PredictionFieldName, null, null);
		writer.WriteProperty(options, PropRandomizeSeed, value.RandomizeSeed, null, null);
		writer.WriteProperty(options, PropSoftTreeDepthLimit, value.SoftTreeDepthLimit, null, null);
		writer.WriteProperty(options, PropSoftTreeDepthTolerance, value.SoftTreeDepthTolerance, null, null);
		writer.WriteProperty(options, PropTrainingPercent, value.TrainingPercent, null, null);
		writer.WriteEndObject();
	}
}

[JsonConverter(typeof(DataframeAnalysisClassificationConverter))]
public sealed partial class DataframeAnalysisClassification
{
	/// <summary>
	/// <para>
	/// Advanced configuration option. Machine learning uses loss guided tree growing, which means that the decision trees grow where the regularized loss decreases most quickly. This parameter affects loss calculations by acting as a multiplier of the tree depth. Higher alpha values result in shallower trees and faster training times. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to zero.
	/// </para>
	/// </summary>
	public double? Alpha { get; set; }
	public string? ClassAssignmentObjective { get; set; }

	/// <summary>
	/// <para>
	/// Defines which field of the document is to be predicted. It must match one of the fields in the index being used to train. If this field is missing from a document, then that document will not be used for training, but a prediction with the trained model will be generated for it. It is also known as continuous target variable.
	/// For classification analysis, the data type of the field must be numeric (<c>integer</c>, <c>short</c>, <c>long</c>, <c>byte</c>), categorical (<c>ip</c> or <c>keyword</c>), or <c>boolean</c>. There must be no more than 30 different values in this field.
	/// For regression analysis, the data type of the field must be numeric.
	/// </para>
	/// </summary>
	public string DependentVariable { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Controls the fraction of data that is used to compute the derivatives of the loss function for tree training. A small value results in the use of a small fraction of the data. If this value is set to be less than 1, accuracy typically improves. However, too small a value may result in poor convergence for the ensemble and so require more trees. By default, this value is calculated during hyperparameter optimization. It must be greater than zero and less than or equal to 1.
	/// </para>
	/// </summary>
	public double? DownsampleFactor { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies whether the training process should finish if it is not finding any better performing models. If disabled, the training process can take significantly longer and the chance of finding a better performing model is unremarkable.
	/// </para>
	/// </summary>
	public bool? EarlyStoppingEnabled { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. The shrinkage applied to the weights. Smaller values result in larger forests which have a better generalization error. However, larger forests cause slower training. By default, this value is calculated during hyperparameter optimization. It must be a value between 0.001 and 1.
	/// </para>
	/// </summary>
	public double? Eta { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies the rate at which <c>eta</c> increases for each new tree that is added to the forest. For example, a rate of 1.05 increases <c>eta</c> by 5% for each extra tree. By default, this value is calculated during hyperparameter optimization. It must be between 0.5 and 2.
	/// </para>
	/// </summary>
	public double? EtaGrowthRatePerTree { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Defines the fraction of features that will be used when selecting a random bag for each candidate split. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public double? FeatureBagFraction { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. A collection of feature preprocessors that modify one or more included fields. The analysis uses the resulting one or more features instead of the original document field. However, these features are ephemeral; they are not stored in the destination index. Multiple <c>feature_processors</c> entries can refer to the same document fields. Automatic categorical feature encoding still occurs for the fields that are unprocessed by a custom processor or that have categorical values. Use this property only if you want to override the automatic feature encoding of the specified fields.
	/// </para>
	/// </summary>
	public ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>? FeatureProcessors { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Regularization parameter to prevent overfitting on the training data set. Multiplies a linear penalty associated with the size of individual trees in the forest. A high gamma value causes training to prefer small trees. A small gamma value results in larger individual trees and slower training. By default, this value is calculated during hyperparameter optimization. It must be a nonnegative value.
	/// </para>
	/// </summary>
	public double? Gamma { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Regularization parameter to prevent overfitting on the training data set. Multiplies an L2 regularization term which applies to leaf weights of the individual trees in the forest. A high lambda value causes training to favor small leaf weights. This behavior makes the prediction function smoother at the expense of potentially not being able to capture relevant relationships between the features and the dependent variable. A small lambda value results in large individual trees and slower training. By default, this value is calculated during hyperparameter optimization. It must be a nonnegative value.
	/// </para>
	/// </summary>
	public double? Lambda { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. A multiplier responsible for determining the maximum number of hyperparameter optimization steps in the Bayesian optimization procedure. The maximum number of steps is determined based on the number of undefined hyperparameters times the maximum optimization rounds per hyperparameter. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public int? MaxOptimizationRoundsPerHyperparameter { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Defines the maximum number of decision trees in the forest. The maximum value is 2000. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public int? MaxTrees { get; set; }

	/// <summary>
	/// <para>
	/// Defines the number of categories for which the predicted probabilities are reported. It must be non-negative or -1. If it is -1 or greater than the total number of categories, probabilities are reported for all categories; if you have a large number of categories, there could be a significant effect on the size of your destination index. NOTE: To use the AUC ROC evaluation method, <c>num_top_classes</c> must be set to -1 or a value greater than or equal to the total number of categories.
	/// </para>
	/// </summary>
	public int? NumTopClasses { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies the maximum number of feature importance values per document to return. By default, no feature importance calculation occurs.
	/// </para>
	/// </summary>
	public int? NumTopFeatureImportanceValues { get; set; }

	/// <summary>
	/// <para>
	/// Defines the name of the prediction field in the results. Defaults to <c>&lt;dependent_variable>_prediction</c>.
	/// </para>
	/// </summary>
	public Elastic.Clients.Elasticsearch.Field? PredictionFieldName { get; set; }

	/// <summary>
	/// <para>
	/// Defines the seed for the random generator that is used to pick training data. By default, it is randomly generated. Set it to a specific value to use the same training data each time you start a job (assuming other related parameters such as <c>source</c> and <c>analyzed_fields</c> are the same).
	/// </para>
	/// </summary>
	public double? RandomizeSeed { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Machine learning uses loss guided tree growing, which means that the decision trees grow where the regularized loss decreases most quickly. This soft limit combines with the <c>soft_tree_depth_tolerance</c> to penalize trees that exceed the specified depth; the regularized loss increases quickly beyond this depth. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to 0.
	/// </para>
	/// </summary>
	public int? SoftTreeDepthLimit { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. This option controls how quickly the regularized loss increases when the tree depth exceeds <c>soft_tree_depth_limit</c>. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to 0.01.
	/// </para>
	/// </summary>
	public double? SoftTreeDepthTolerance { get; set; }

	/// <summary>
	/// <para>
	/// Defines what percentage of the eligible documents that will be used for training. Documents that are ignored by the analysis (for example those that contain arrays with more than one value) won’t be included in the calculation for used percentage.
	/// </para>
	/// </summary>
	public double? TrainingPercent { get; set; }

	public static implicit operator Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysis(DataframeAnalysisClassification dataframeAnalysisClassification) => Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysis.Classification(dataframeAnalysisClassification);
}

public sealed partial class DataframeAnalysisClassificationDescriptor<TDocument> : SerializableDescriptor<DataframeAnalysisClassificationDescriptor<TDocument>>
{
	internal DataframeAnalysisClassificationDescriptor(Action<DataframeAnalysisClassificationDescriptor<TDocument>> configure) => configure.Invoke(this);

	public DataframeAnalysisClassificationDescriptor() : base()
	{
	}

	private double? AlphaValue { get; set; }
	private string? ClassAssignmentObjectiveValue { get; set; }
	private string DependentVariableValue { get; set; }
	private double? DownsampleFactorValue { get; set; }
	private bool? EarlyStoppingEnabledValue { get; set; }
	private double? EtaValue { get; set; }
	private double? EtaGrowthRatePerTreeValue { get; set; }
	private double? FeatureBagFractionValue { get; set; }
	private ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>? FeatureProcessorsValue { get; set; }
	private Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument> FeatureProcessorsDescriptor { get; set; }
	private Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument>> FeatureProcessorsDescriptorAction { get; set; }
	private Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument>>[] FeatureProcessorsDescriptorActions { get; set; }
	private double? GammaValue { get; set; }
	private double? LambdaValue { get; set; }
	private int? MaxOptimizationRoundsPerHyperparameterValue { get; set; }
	private int? MaxTreesValue { get; set; }
	private int? NumTopClassesValue { get; set; }
	private int? NumTopFeatureImportanceValuesValue { get; set; }
	private Elastic.Clients.Elasticsearch.Field? PredictionFieldNameValue { get; set; }
	private double? RandomizeSeedValue { get; set; }
	private int? SoftTreeDepthLimitValue { get; set; }
	private double? SoftTreeDepthToleranceValue { get; set; }
	private double? TrainingPercentValue { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Machine learning uses loss guided tree growing, which means that the decision trees grow where the regularized loss decreases most quickly. This parameter affects loss calculations by acting as a multiplier of the tree depth. Higher alpha values result in shallower trees and faster training times. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to zero.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> Alpha(double? alpha)
	{
		AlphaValue = alpha;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor<TDocument> ClassAssignmentObjective(string? classAssignmentObjective)
	{
		ClassAssignmentObjectiveValue = classAssignmentObjective;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines which field of the document is to be predicted. It must match one of the fields in the index being used to train. If this field is missing from a document, then that document will not be used for training, but a prediction with the trained model will be generated for it. It is also known as continuous target variable.
	/// For classification analysis, the data type of the field must be numeric (<c>integer</c>, <c>short</c>, <c>long</c>, <c>byte</c>), categorical (<c>ip</c> or <c>keyword</c>), or <c>boolean</c>. There must be no more than 30 different values in this field.
	/// For regression analysis, the data type of the field must be numeric.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> DependentVariable(string dependentVariable)
	{
		DependentVariableValue = dependentVariable;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Controls the fraction of data that is used to compute the derivatives of the loss function for tree training. A small value results in the use of a small fraction of the data. If this value is set to be less than 1, accuracy typically improves. However, too small a value may result in poor convergence for the ensemble and so require more trees. By default, this value is calculated during hyperparameter optimization. It must be greater than zero and less than or equal to 1.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> DownsampleFactor(double? downsampleFactor)
	{
		DownsampleFactorValue = downsampleFactor;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies whether the training process should finish if it is not finding any better performing models. If disabled, the training process can take significantly longer and the chance of finding a better performing model is unremarkable.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> EarlyStoppingEnabled(bool? earlyStoppingEnabled = true)
	{
		EarlyStoppingEnabledValue = earlyStoppingEnabled;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. The shrinkage applied to the weights. Smaller values result in larger forests which have a better generalization error. However, larger forests cause slower training. By default, this value is calculated during hyperparameter optimization. It must be a value between 0.001 and 1.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> Eta(double? eta)
	{
		EtaValue = eta;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies the rate at which <c>eta</c> increases for each new tree that is added to the forest. For example, a rate of 1.05 increases <c>eta</c> by 5% for each extra tree. By default, this value is calculated during hyperparameter optimization. It must be between 0.5 and 2.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> EtaGrowthRatePerTree(double? etaGrowthRatePerTree)
	{
		EtaGrowthRatePerTreeValue = etaGrowthRatePerTree;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Defines the fraction of features that will be used when selecting a random bag for each candidate split. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> FeatureBagFraction(double? featureBagFraction)
	{
		FeatureBagFractionValue = featureBagFraction;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. A collection of feature preprocessors that modify one or more included fields. The analysis uses the resulting one or more features instead of the original document field. However, these features are ephemeral; they are not stored in the destination index. Multiple <c>feature_processors</c> entries can refer to the same document fields. Automatic categorical feature encoding still occurs for the fields that are unprocessed by a custom processor or that have categorical values. Use this property only if you want to override the automatic feature encoding of the specified fields.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> FeatureProcessors(ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>? featureProcessors)
	{
		FeatureProcessorsDescriptor = null;
		FeatureProcessorsDescriptorAction = null;
		FeatureProcessorsDescriptorActions = null;
		FeatureProcessorsValue = featureProcessors;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor<TDocument> FeatureProcessors(Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument> descriptor)
	{
		FeatureProcessorsValue = null;
		FeatureProcessorsDescriptorAction = null;
		FeatureProcessorsDescriptorActions = null;
		FeatureProcessorsDescriptor = descriptor;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor<TDocument> FeatureProcessors(Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument>> configure)
	{
		FeatureProcessorsValue = null;
		FeatureProcessorsDescriptor = null;
		FeatureProcessorsDescriptorActions = null;
		FeatureProcessorsDescriptorAction = configure;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor<TDocument> FeatureProcessors(params Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument>>[] configure)
	{
		FeatureProcessorsValue = null;
		FeatureProcessorsDescriptor = null;
		FeatureProcessorsDescriptorAction = null;
		FeatureProcessorsDescriptorActions = configure;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Regularization parameter to prevent overfitting on the training data set. Multiplies a linear penalty associated with the size of individual trees in the forest. A high gamma value causes training to prefer small trees. A small gamma value results in larger individual trees and slower training. By default, this value is calculated during hyperparameter optimization. It must be a nonnegative value.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> Gamma(double? gamma)
	{
		GammaValue = gamma;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Regularization parameter to prevent overfitting on the training data set. Multiplies an L2 regularization term which applies to leaf weights of the individual trees in the forest. A high lambda value causes training to favor small leaf weights. This behavior makes the prediction function smoother at the expense of potentially not being able to capture relevant relationships between the features and the dependent variable. A small lambda value results in large individual trees and slower training. By default, this value is calculated during hyperparameter optimization. It must be a nonnegative value.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> Lambda(double? lambda)
	{
		LambdaValue = lambda;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. A multiplier responsible for determining the maximum number of hyperparameter optimization steps in the Bayesian optimization procedure. The maximum number of steps is determined based on the number of undefined hyperparameters times the maximum optimization rounds per hyperparameter. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> MaxOptimizationRoundsPerHyperparameter(int? maxOptimizationRoundsPerHyperparameter)
	{
		MaxOptimizationRoundsPerHyperparameterValue = maxOptimizationRoundsPerHyperparameter;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Defines the maximum number of decision trees in the forest. The maximum value is 2000. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> MaxTrees(int? maxTrees)
	{
		MaxTreesValue = maxTrees;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the number of categories for which the predicted probabilities are reported. It must be non-negative or -1. If it is -1 or greater than the total number of categories, probabilities are reported for all categories; if you have a large number of categories, there could be a significant effect on the size of your destination index. NOTE: To use the AUC ROC evaluation method, <c>num_top_classes</c> must be set to -1 or a value greater than or equal to the total number of categories.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> NumTopClasses(int? numTopClasses)
	{
		NumTopClassesValue = numTopClasses;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies the maximum number of feature importance values per document to return. By default, no feature importance calculation occurs.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> NumTopFeatureImportanceValues(int? numTopFeatureImportanceValues)
	{
		NumTopFeatureImportanceValuesValue = numTopFeatureImportanceValues;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the name of the prediction field in the results. Defaults to <c>&lt;dependent_variable>_prediction</c>.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> PredictionFieldName(Elastic.Clients.Elasticsearch.Field? predictionFieldName)
	{
		PredictionFieldNameValue = predictionFieldName;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the name of the prediction field in the results. Defaults to <c>&lt;dependent_variable>_prediction</c>.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> PredictionFieldName<TValue>(Expression<Func<TDocument, TValue>> predictionFieldName)
	{
		PredictionFieldNameValue = predictionFieldName;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the name of the prediction field in the results. Defaults to <c>&lt;dependent_variable>_prediction</c>.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> PredictionFieldName(Expression<Func<TDocument, object>> predictionFieldName)
	{
		PredictionFieldNameValue = predictionFieldName;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the seed for the random generator that is used to pick training data. By default, it is randomly generated. Set it to a specific value to use the same training data each time you start a job (assuming other related parameters such as <c>source</c> and <c>analyzed_fields</c> are the same).
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> RandomizeSeed(double? randomizeSeed)
	{
		RandomizeSeedValue = randomizeSeed;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Machine learning uses loss guided tree growing, which means that the decision trees grow where the regularized loss decreases most quickly. This soft limit combines with the <c>soft_tree_depth_tolerance</c> to penalize trees that exceed the specified depth; the regularized loss increases quickly beyond this depth. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to 0.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> SoftTreeDepthLimit(int? softTreeDepthLimit)
	{
		SoftTreeDepthLimitValue = softTreeDepthLimit;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. This option controls how quickly the regularized loss increases when the tree depth exceeds <c>soft_tree_depth_limit</c>. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to 0.01.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> SoftTreeDepthTolerance(double? softTreeDepthTolerance)
	{
		SoftTreeDepthToleranceValue = softTreeDepthTolerance;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines what percentage of the eligible documents that will be used for training. Documents that are ignored by the analysis (for example those that contain arrays with more than one value) won’t be included in the calculation for used percentage.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor<TDocument> TrainingPercent(double? trainingPercent)
	{
		TrainingPercentValue = trainingPercent;
		return Self;
	}

	protected override void Serialize(Utf8JsonWriter writer, JsonSerializerOptions options, IElasticsearchClientSettings settings)
	{
		writer.WriteStartObject();
		if (AlphaValue.HasValue)
		{
			writer.WritePropertyName("alpha");
			writer.WriteNumberValue(AlphaValue.Value);
		}

		if (!string.IsNullOrEmpty(ClassAssignmentObjectiveValue))
		{
			writer.WritePropertyName("class_assignment_objective");
			writer.WriteStringValue(ClassAssignmentObjectiveValue);
		}

		writer.WritePropertyName("dependent_variable");
		writer.WriteStringValue(DependentVariableValue);
		if (DownsampleFactorValue.HasValue)
		{
			writer.WritePropertyName("downsample_factor");
			writer.WriteNumberValue(DownsampleFactorValue.Value);
		}

		if (EarlyStoppingEnabledValue.HasValue)
		{
			writer.WritePropertyName("early_stopping_enabled");
			writer.WriteBooleanValue(EarlyStoppingEnabledValue.Value);
		}

		if (EtaValue.HasValue)
		{
			writer.WritePropertyName("eta");
			writer.WriteNumberValue(EtaValue.Value);
		}

		if (EtaGrowthRatePerTreeValue.HasValue)
		{
			writer.WritePropertyName("eta_growth_rate_per_tree");
			writer.WriteNumberValue(EtaGrowthRatePerTreeValue.Value);
		}

		if (FeatureBagFractionValue.HasValue)
		{
			writer.WritePropertyName("feature_bag_fraction");
			writer.WriteNumberValue(FeatureBagFractionValue.Value);
		}

		if (FeatureProcessorsDescriptor is not null)
		{
			writer.WritePropertyName("feature_processors");
			writer.WriteStartArray();
			JsonSerializer.Serialize(writer, FeatureProcessorsDescriptor, options);
			writer.WriteEndArray();
		}
		else if (FeatureProcessorsDescriptorAction is not null)
		{
			writer.WritePropertyName("feature_processors");
			writer.WriteStartArray();
			JsonSerializer.Serialize(writer, new Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument>(FeatureProcessorsDescriptorAction), options);
			writer.WriteEndArray();
		}
		else if (FeatureProcessorsDescriptorActions is not null)
		{
			writer.WritePropertyName("feature_processors");
			writer.WriteStartArray();
			foreach (var action in FeatureProcessorsDescriptorActions)
			{
				JsonSerializer.Serialize(writer, new Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor<TDocument>(action), options);
			}

			writer.WriteEndArray();
		}
		else if (FeatureProcessorsValue is not null)
		{
			writer.WritePropertyName("feature_processors");
			JsonSerializer.Serialize(writer, FeatureProcessorsValue, options);
		}

		if (GammaValue.HasValue)
		{
			writer.WritePropertyName("gamma");
			writer.WriteNumberValue(GammaValue.Value);
		}

		if (LambdaValue.HasValue)
		{
			writer.WritePropertyName("lambda");
			writer.WriteNumberValue(LambdaValue.Value);
		}

		if (MaxOptimizationRoundsPerHyperparameterValue.HasValue)
		{
			writer.WritePropertyName("max_optimization_rounds_per_hyperparameter");
			writer.WriteNumberValue(MaxOptimizationRoundsPerHyperparameterValue.Value);
		}

		if (MaxTreesValue.HasValue)
		{
			writer.WritePropertyName("max_trees");
			writer.WriteNumberValue(MaxTreesValue.Value);
		}

		if (NumTopClassesValue.HasValue)
		{
			writer.WritePropertyName("num_top_classes");
			writer.WriteNumberValue(NumTopClassesValue.Value);
		}

		if (NumTopFeatureImportanceValuesValue.HasValue)
		{
			writer.WritePropertyName("num_top_feature_importance_values");
			writer.WriteNumberValue(NumTopFeatureImportanceValuesValue.Value);
		}

		if (PredictionFieldNameValue is not null)
		{
			writer.WritePropertyName("prediction_field_name");
			JsonSerializer.Serialize(writer, PredictionFieldNameValue, options);
		}

		if (RandomizeSeedValue.HasValue)
		{
			writer.WritePropertyName("randomize_seed");
			writer.WriteNumberValue(RandomizeSeedValue.Value);
		}

		if (SoftTreeDepthLimitValue.HasValue)
		{
			writer.WritePropertyName("soft_tree_depth_limit");
			writer.WriteNumberValue(SoftTreeDepthLimitValue.Value);
		}

		if (SoftTreeDepthToleranceValue.HasValue)
		{
			writer.WritePropertyName("soft_tree_depth_tolerance");
			writer.WriteNumberValue(SoftTreeDepthToleranceValue.Value);
		}

		if (TrainingPercentValue.HasValue)
		{
			writer.WritePropertyName("training_percent");
			writer.WriteNumberValue(TrainingPercentValue.Value);
		}

		writer.WriteEndObject();
	}
}

public sealed partial class DataframeAnalysisClassificationDescriptor : SerializableDescriptor<DataframeAnalysisClassificationDescriptor>
{
	internal DataframeAnalysisClassificationDescriptor(Action<DataframeAnalysisClassificationDescriptor> configure) => configure.Invoke(this);

	public DataframeAnalysisClassificationDescriptor() : base()
	{
	}

	private double? AlphaValue { get; set; }
	private string? ClassAssignmentObjectiveValue { get; set; }
	private string DependentVariableValue { get; set; }
	private double? DownsampleFactorValue { get; set; }
	private bool? EarlyStoppingEnabledValue { get; set; }
	private double? EtaValue { get; set; }
	private double? EtaGrowthRatePerTreeValue { get; set; }
	private double? FeatureBagFractionValue { get; set; }
	private ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>? FeatureProcessorsValue { get; set; }
	private Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor FeatureProcessorsDescriptor { get; set; }
	private Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor> FeatureProcessorsDescriptorAction { get; set; }
	private Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor>[] FeatureProcessorsDescriptorActions { get; set; }
	private double? GammaValue { get; set; }
	private double? LambdaValue { get; set; }
	private int? MaxOptimizationRoundsPerHyperparameterValue { get; set; }
	private int? MaxTreesValue { get; set; }
	private int? NumTopClassesValue { get; set; }
	private int? NumTopFeatureImportanceValuesValue { get; set; }
	private Elastic.Clients.Elasticsearch.Field? PredictionFieldNameValue { get; set; }
	private double? RandomizeSeedValue { get; set; }
	private int? SoftTreeDepthLimitValue { get; set; }
	private double? SoftTreeDepthToleranceValue { get; set; }
	private double? TrainingPercentValue { get; set; }

	/// <summary>
	/// <para>
	/// Advanced configuration option. Machine learning uses loss guided tree growing, which means that the decision trees grow where the regularized loss decreases most quickly. This parameter affects loss calculations by acting as a multiplier of the tree depth. Higher alpha values result in shallower trees and faster training times. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to zero.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor Alpha(double? alpha)
	{
		AlphaValue = alpha;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor ClassAssignmentObjective(string? classAssignmentObjective)
	{
		ClassAssignmentObjectiveValue = classAssignmentObjective;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines which field of the document is to be predicted. It must match one of the fields in the index being used to train. If this field is missing from a document, then that document will not be used for training, but a prediction with the trained model will be generated for it. It is also known as continuous target variable.
	/// For classification analysis, the data type of the field must be numeric (<c>integer</c>, <c>short</c>, <c>long</c>, <c>byte</c>), categorical (<c>ip</c> or <c>keyword</c>), or <c>boolean</c>. There must be no more than 30 different values in this field.
	/// For regression analysis, the data type of the field must be numeric.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor DependentVariable(string dependentVariable)
	{
		DependentVariableValue = dependentVariable;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Controls the fraction of data that is used to compute the derivatives of the loss function for tree training. A small value results in the use of a small fraction of the data. If this value is set to be less than 1, accuracy typically improves. However, too small a value may result in poor convergence for the ensemble and so require more trees. By default, this value is calculated during hyperparameter optimization. It must be greater than zero and less than or equal to 1.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor DownsampleFactor(double? downsampleFactor)
	{
		DownsampleFactorValue = downsampleFactor;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies whether the training process should finish if it is not finding any better performing models. If disabled, the training process can take significantly longer and the chance of finding a better performing model is unremarkable.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor EarlyStoppingEnabled(bool? earlyStoppingEnabled = true)
	{
		EarlyStoppingEnabledValue = earlyStoppingEnabled;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. The shrinkage applied to the weights. Smaller values result in larger forests which have a better generalization error. However, larger forests cause slower training. By default, this value is calculated during hyperparameter optimization. It must be a value between 0.001 and 1.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor Eta(double? eta)
	{
		EtaValue = eta;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies the rate at which <c>eta</c> increases for each new tree that is added to the forest. For example, a rate of 1.05 increases <c>eta</c> by 5% for each extra tree. By default, this value is calculated during hyperparameter optimization. It must be between 0.5 and 2.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor EtaGrowthRatePerTree(double? etaGrowthRatePerTree)
	{
		EtaGrowthRatePerTreeValue = etaGrowthRatePerTree;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Defines the fraction of features that will be used when selecting a random bag for each candidate split. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor FeatureBagFraction(double? featureBagFraction)
	{
		FeatureBagFractionValue = featureBagFraction;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. A collection of feature preprocessors that modify one or more included fields. The analysis uses the resulting one or more features instead of the original document field. However, these features are ephemeral; they are not stored in the destination index. Multiple <c>feature_processors</c> entries can refer to the same document fields. Automatic categorical feature encoding still occurs for the fields that are unprocessed by a custom processor or that have categorical values. Use this property only if you want to override the automatic feature encoding of the specified fields.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor FeatureProcessors(ICollection<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessor>? featureProcessors)
	{
		FeatureProcessorsDescriptor = null;
		FeatureProcessorsDescriptorAction = null;
		FeatureProcessorsDescriptorActions = null;
		FeatureProcessorsValue = featureProcessors;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor FeatureProcessors(Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor descriptor)
	{
		FeatureProcessorsValue = null;
		FeatureProcessorsDescriptorAction = null;
		FeatureProcessorsDescriptorActions = null;
		FeatureProcessorsDescriptor = descriptor;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor FeatureProcessors(Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor> configure)
	{
		FeatureProcessorsValue = null;
		FeatureProcessorsDescriptor = null;
		FeatureProcessorsDescriptorActions = null;
		FeatureProcessorsDescriptorAction = configure;
		return Self;
	}

	public DataframeAnalysisClassificationDescriptor FeatureProcessors(params Action<Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor>[] configure)
	{
		FeatureProcessorsValue = null;
		FeatureProcessorsDescriptor = null;
		FeatureProcessorsDescriptorAction = null;
		FeatureProcessorsDescriptorActions = configure;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Regularization parameter to prevent overfitting on the training data set. Multiplies a linear penalty associated with the size of individual trees in the forest. A high gamma value causes training to prefer small trees. A small gamma value results in larger individual trees and slower training. By default, this value is calculated during hyperparameter optimization. It must be a nonnegative value.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor Gamma(double? gamma)
	{
		GammaValue = gamma;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Regularization parameter to prevent overfitting on the training data set. Multiplies an L2 regularization term which applies to leaf weights of the individual trees in the forest. A high lambda value causes training to favor small leaf weights. This behavior makes the prediction function smoother at the expense of potentially not being able to capture relevant relationships between the features and the dependent variable. A small lambda value results in large individual trees and slower training. By default, this value is calculated during hyperparameter optimization. It must be a nonnegative value.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor Lambda(double? lambda)
	{
		LambdaValue = lambda;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. A multiplier responsible for determining the maximum number of hyperparameter optimization steps in the Bayesian optimization procedure. The maximum number of steps is determined based on the number of undefined hyperparameters times the maximum optimization rounds per hyperparameter. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor MaxOptimizationRoundsPerHyperparameter(int? maxOptimizationRoundsPerHyperparameter)
	{
		MaxOptimizationRoundsPerHyperparameterValue = maxOptimizationRoundsPerHyperparameter;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Defines the maximum number of decision trees in the forest. The maximum value is 2000. By default, this value is calculated during hyperparameter optimization.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor MaxTrees(int? maxTrees)
	{
		MaxTreesValue = maxTrees;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the number of categories for which the predicted probabilities are reported. It must be non-negative or -1. If it is -1 or greater than the total number of categories, probabilities are reported for all categories; if you have a large number of categories, there could be a significant effect on the size of your destination index. NOTE: To use the AUC ROC evaluation method, <c>num_top_classes</c> must be set to -1 or a value greater than or equal to the total number of categories.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor NumTopClasses(int? numTopClasses)
	{
		NumTopClassesValue = numTopClasses;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Specifies the maximum number of feature importance values per document to return. By default, no feature importance calculation occurs.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor NumTopFeatureImportanceValues(int? numTopFeatureImportanceValues)
	{
		NumTopFeatureImportanceValuesValue = numTopFeatureImportanceValues;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the name of the prediction field in the results. Defaults to <c>&lt;dependent_variable>_prediction</c>.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor PredictionFieldName(Elastic.Clients.Elasticsearch.Field? predictionFieldName)
	{
		PredictionFieldNameValue = predictionFieldName;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the name of the prediction field in the results. Defaults to <c>&lt;dependent_variable>_prediction</c>.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor PredictionFieldName<TDocument, TValue>(Expression<Func<TDocument, TValue>> predictionFieldName)
	{
		PredictionFieldNameValue = predictionFieldName;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the name of the prediction field in the results. Defaults to <c>&lt;dependent_variable>_prediction</c>.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor PredictionFieldName<TDocument>(Expression<Func<TDocument, object>> predictionFieldName)
	{
		PredictionFieldNameValue = predictionFieldName;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines the seed for the random generator that is used to pick training data. By default, it is randomly generated. Set it to a specific value to use the same training data each time you start a job (assuming other related parameters such as <c>source</c> and <c>analyzed_fields</c> are the same).
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor RandomizeSeed(double? randomizeSeed)
	{
		RandomizeSeedValue = randomizeSeed;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. Machine learning uses loss guided tree growing, which means that the decision trees grow where the regularized loss decreases most quickly. This soft limit combines with the <c>soft_tree_depth_tolerance</c> to penalize trees that exceed the specified depth; the regularized loss increases quickly beyond this depth. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to 0.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor SoftTreeDepthLimit(int? softTreeDepthLimit)
	{
		SoftTreeDepthLimitValue = softTreeDepthLimit;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Advanced configuration option. This option controls how quickly the regularized loss increases when the tree depth exceeds <c>soft_tree_depth_limit</c>. By default, this value is calculated during hyperparameter optimization. It must be greater than or equal to 0.01.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor SoftTreeDepthTolerance(double? softTreeDepthTolerance)
	{
		SoftTreeDepthToleranceValue = softTreeDepthTolerance;
		return Self;
	}

	/// <summary>
	/// <para>
	/// Defines what percentage of the eligible documents that will be used for training. Documents that are ignored by the analysis (for example those that contain arrays with more than one value) won’t be included in the calculation for used percentage.
	/// </para>
	/// </summary>
	public DataframeAnalysisClassificationDescriptor TrainingPercent(double? trainingPercent)
	{
		TrainingPercentValue = trainingPercent;
		return Self;
	}

	protected override void Serialize(Utf8JsonWriter writer, JsonSerializerOptions options, IElasticsearchClientSettings settings)
	{
		writer.WriteStartObject();
		if (AlphaValue.HasValue)
		{
			writer.WritePropertyName("alpha");
			writer.WriteNumberValue(AlphaValue.Value);
		}

		if (!string.IsNullOrEmpty(ClassAssignmentObjectiveValue))
		{
			writer.WritePropertyName("class_assignment_objective");
			writer.WriteStringValue(ClassAssignmentObjectiveValue);
		}

		writer.WritePropertyName("dependent_variable");
		writer.WriteStringValue(DependentVariableValue);
		if (DownsampleFactorValue.HasValue)
		{
			writer.WritePropertyName("downsample_factor");
			writer.WriteNumberValue(DownsampleFactorValue.Value);
		}

		if (EarlyStoppingEnabledValue.HasValue)
		{
			writer.WritePropertyName("early_stopping_enabled");
			writer.WriteBooleanValue(EarlyStoppingEnabledValue.Value);
		}

		if (EtaValue.HasValue)
		{
			writer.WritePropertyName("eta");
			writer.WriteNumberValue(EtaValue.Value);
		}

		if (EtaGrowthRatePerTreeValue.HasValue)
		{
			writer.WritePropertyName("eta_growth_rate_per_tree");
			writer.WriteNumberValue(EtaGrowthRatePerTreeValue.Value);
		}

		if (FeatureBagFractionValue.HasValue)
		{
			writer.WritePropertyName("feature_bag_fraction");
			writer.WriteNumberValue(FeatureBagFractionValue.Value);
		}

		if (FeatureProcessorsDescriptor is not null)
		{
			writer.WritePropertyName("feature_processors");
			writer.WriteStartArray();
			JsonSerializer.Serialize(writer, FeatureProcessorsDescriptor, options);
			writer.WriteEndArray();
		}
		else if (FeatureProcessorsDescriptorAction is not null)
		{
			writer.WritePropertyName("feature_processors");
			writer.WriteStartArray();
			JsonSerializer.Serialize(writer, new Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor(FeatureProcessorsDescriptorAction), options);
			writer.WriteEndArray();
		}
		else if (FeatureProcessorsDescriptorActions is not null)
		{
			writer.WritePropertyName("feature_processors");
			writer.WriteStartArray();
			foreach (var action in FeatureProcessorsDescriptorActions)
			{
				JsonSerializer.Serialize(writer, new Elastic.Clients.Elasticsearch.MachineLearning.DataframeAnalysisFeatureProcessorDescriptor(action), options);
			}

			writer.WriteEndArray();
		}
		else if (FeatureProcessorsValue is not null)
		{
			writer.WritePropertyName("feature_processors");
			JsonSerializer.Serialize(writer, FeatureProcessorsValue, options);
		}

		if (GammaValue.HasValue)
		{
			writer.WritePropertyName("gamma");
			writer.WriteNumberValue(GammaValue.Value);
		}

		if (LambdaValue.HasValue)
		{
			writer.WritePropertyName("lambda");
			writer.WriteNumberValue(LambdaValue.Value);
		}

		if (MaxOptimizationRoundsPerHyperparameterValue.HasValue)
		{
			writer.WritePropertyName("max_optimization_rounds_per_hyperparameter");
			writer.WriteNumberValue(MaxOptimizationRoundsPerHyperparameterValue.Value);
		}

		if (MaxTreesValue.HasValue)
		{
			writer.WritePropertyName("max_trees");
			writer.WriteNumberValue(MaxTreesValue.Value);
		}

		if (NumTopClassesValue.HasValue)
		{
			writer.WritePropertyName("num_top_classes");
			writer.WriteNumberValue(NumTopClassesValue.Value);
		}

		if (NumTopFeatureImportanceValuesValue.HasValue)
		{
			writer.WritePropertyName("num_top_feature_importance_values");
			writer.WriteNumberValue(NumTopFeatureImportanceValuesValue.Value);
		}

		if (PredictionFieldNameValue is not null)
		{
			writer.WritePropertyName("prediction_field_name");
			JsonSerializer.Serialize(writer, PredictionFieldNameValue, options);
		}

		if (RandomizeSeedValue.HasValue)
		{
			writer.WritePropertyName("randomize_seed");
			writer.WriteNumberValue(RandomizeSeedValue.Value);
		}

		if (SoftTreeDepthLimitValue.HasValue)
		{
			writer.WritePropertyName("soft_tree_depth_limit");
			writer.WriteNumberValue(SoftTreeDepthLimitValue.Value);
		}

		if (SoftTreeDepthToleranceValue.HasValue)
		{
			writer.WritePropertyName("soft_tree_depth_tolerance");
			writer.WriteNumberValue(SoftTreeDepthToleranceValue.Value);
		}

		if (TrainingPercentValue.HasValue)
		{
			writer.WritePropertyName("training_percent");
			writer.WriteNumberValue(TrainingPercentValue.Value);
		}

		writer.WriteEndObject();
	}
}